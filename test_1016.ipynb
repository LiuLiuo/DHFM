{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This source code is licensed under the license found in the\n",
    "LICENSE file in the root directory of this source tree.\n",
    "'''\n",
    "\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import subprocess\n",
    "from pytorch_transformers import *\n",
    "import random\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import wordnet as wn\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "pos_converter = {'NOUN':'n', 'PROPN':'n', 'VERB':'v', 'AUX':'v', 'ADJ':'a', 'ADV':'r'}\n",
    "\n",
    "def generate_key(lemma, pos):\n",
    "    if pos in pos_converter.keys():\n",
    "        pos = pos_converter[pos]\n",
    "    key = '{}+{}'.format(lemma, pos)\n",
    "    return key\n",
    "\n",
    "def load_pretrained_model(name):\n",
    "    if name == 'roberta-base':\n",
    "        # model = RobertaModel.from_pretrained('roberta-base')\n",
    "        model = RobertaModel.from_pretrained('roberta-base', output_hidden_states=True)\n",
    "        hdim = 768\n",
    "    elif name == 'roberta-large':\n",
    "        # model = RobertaModel.from_pretrained('roberta-large')\n",
    "        model = RobertaModel.from_pretrained('roberta-large', output_hidden_states=True)\n",
    "        hdim = 1024\n",
    "    elif name == 'xlmroberta-base':\n",
    "        model = AutoModel.from_pretrained(\"xlm-roberta-base\", output_hidden_states=True)\n",
    "        hdim = 768\n",
    "    elif name == 'xlmroberta-large':\n",
    "        model = AutoModel.from_pretrained(\"xlm-roberta-large\", output_hidden_states=True)\n",
    "        hdim = 1024\n",
    "    elif name == 'bert-large':\n",
    "        model = BertModel.from_pretrained('bert-large-cased', output_hidden_states=True)\n",
    "        hdim = 1024\n",
    "    else: #bert base\n",
    "        model = BertModel.from_pretrained('bert-base-cased', output_hidden_states=True)\n",
    "        hdim = 768\n",
    "    return model, hdim\n",
    "\n",
    "def load_tokenizer(name):\n",
    "    if name == 'roberta-base':\n",
    "        tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "    elif name == 'roberta-large':\n",
    "        tokenizer = RobertaTokenizer.from_pretrained('roberta-large')\n",
    "    elif name == 'xlmroberta-base':\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "    elif name == 'xlmroberta-large':\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-large\")\n",
    "    elif name == 'bert-large':\n",
    "        tokenizer = BertTokenizer.from_pretrained('bert-large-cased')\n",
    "    else: #bert base\n",
    "        tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "    return tokenizer\n",
    "\n",
    "def load_wn_senses(path):\n",
    "    wn_senses = {}\n",
    "    with open(path, 'r', encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip().split('\\t')\n",
    "            lemma = line[0]\n",
    "            pos = line[1]\n",
    "            senses = line[2:]\n",
    "\n",
    "            key = generate_key(lemma, pos)\n",
    "            wn_senses[key] = senses\n",
    "    return wn_senses\n",
    "\n",
    "def get_label_space(data):\n",
    "    #get set of labels from dataset\n",
    "    labels = set()\n",
    "\n",
    "    for sent in data:\n",
    "        for _, _, _, _, label in sent:\n",
    "            if label != -1:\n",
    "                labels.add(label)\n",
    "\n",
    "    labels = list(labels)\n",
    "    labels.sort()\n",
    "    labels.append('n/a')\n",
    "\n",
    "    label_map = {}\n",
    "    for sent in data:\n",
    "        for _, lemma, pos, _, label in sent:\n",
    "            if label != -1:\n",
    "                key = generate_key(lemma, pos)\n",
    "                label_idx = labels.index(label)\n",
    "                if key not in label_map: label_map[key] = set()\n",
    "                label_map[key].add(label_idx)\n",
    "\n",
    "    return labels, label_map\n",
    "\n",
    "def process_encoder_outputs(output, mask, as_tensor=False):\n",
    "    combined_outputs = []\n",
    "    position = -1\n",
    "    avg_arr = []\n",
    "    for idx, rep in zip(mask, torch.split(output, 1, dim=0)):\n",
    "        #ignore unlabeled words\n",
    "        if idx == -1: continue\n",
    "        #average representations for units in same example\n",
    "        elif position < idx:\n",
    "            position=idx\n",
    "            if len(avg_arr) > 0: combined_outputs.append(torch.mean(torch.stack(avg_arr, dim=-1), dim=-1))\n",
    "            avg_arr = [rep]\n",
    "        else:\n",
    "            assert position == idx\n",
    "            avg_arr.append(rep)\n",
    "    #get last example from avg_arr\n",
    "    if len(avg_arr) > 0: combined_outputs.append(torch.mean(torch.stack(avg_arr, dim=-1), dim=-1))\n",
    "    if as_tensor: return torch.cat(combined_outputs, dim=0)\n",
    "    else: return combined_outputs\n",
    "\n",
    "#run WSD Evaluation Framework scorer within python\n",
    "def evaluate_output(scorer_path, gold_filepath, out_filepath):\n",
    "    eval_cmd = ['java','-cp', scorer_path, 'Scorer', gold_filepath, out_filepath]\n",
    "    output = subprocess.Popen(eval_cmd, stdout=subprocess.PIPE ).communicate()[0]\n",
    "    output = [x.decode(\"utf-8\") for x in output.splitlines()]\n",
    "    p, r, f1 = [float(output[i].split('=')[-1].strip()[:-1]) for i in range(3)]\n",
    "    return p, r, f1\n",
    "\n",
    "def get_adj_keys():\n",
    "    key_list = []\n",
    "    for synset in wn.all_synsets('a'):\n",
    "        for lemma in synset.lemmas():\n",
    "            key_list.extend([lemma.key()])\n",
    "    return key_list\n",
    "\n",
    "def load_data(datapath, name, train_sent=None):\n",
    "    if 'wngt' in name:\n",
    "        name, new_name = name.split('-')\n",
    "    else:\n",
    "        name, new_name = name, ''\n",
    "    text_path = os.path.join(datapath, '{}.data.test.xml'.format(name))\n",
    "    gold_path = os.path.join(datapath, '{}.gold.key.txt'.format(name))\n",
    "\n",
    "    #load gold labels\n",
    "    gold_labels = {}\n",
    "    with open(gold_path, 'r', encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip().split(' ')\n",
    "            instance = line[0]\n",
    "            #this means we are ignoring other senses if labeled with more than one\n",
    "            #(happens at least in SemCor data)\n",
    "            key = line[1]\n",
    "            gold_labels[instance] = key\n",
    "\n",
    "    #load train examples + annotate sense instances with gold labels\n",
    "    sentences = []\n",
    "    s = []\n",
    "    with open(text_path, 'r', encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line == '</sentence>':\n",
    "                sentences.append(s)\n",
    "                s=[]\n",
    "                if 'semcor' in name and len(sentences) >= train_sent:\n",
    "                    break\n",
    "\n",
    "            elif line.startswith('<instance') or line.startswith('<wf'):\n",
    "                word = re.search('>(.+?)<', line).group(1)\n",
    "                # print(line)\n",
    "                try:\n",
    "                    lemma = re.search('lemma=\"(.+?)\"', line).group(1)\n",
    "                except AttributeError:\n",
    "                    lemma = word.lower()\n",
    "                pos = re.search('pos=\"(.+?)\"', line).group(1)\n",
    "\n",
    "                #clean up data\n",
    "                word = re.sub('&apos;', '\\'', word)\n",
    "                lemma = re.sub('&apos;', '\\'', lemma).lower()\n",
    "\n",
    "                sense_inst = -1\n",
    "                sense_label = -1\n",
    "                if line.startswith('<instance'):\n",
    "                    sense_inst = re.search('instance id=\"(.+?)\"', line).group(1)\n",
    "                    #annotate sense instance with gold label\n",
    "                    sense_label = gold_labels.get(sense_inst)\n",
    "                    sense_label = sense_label if sense_label else -1\n",
    "                s.append((word, lemma, pos, sense_inst, sense_label))\n",
    "    if new_name and 'semcor' in name:\n",
    "        # sent_num = 0\n",
    "        extra_path = os.path.join(datapath, '{}.xml'.format(new_name))\n",
    "        wngt_corpus = open(extra_path, 'r').read()\n",
    "        wsd_bs = BeautifulSoup(wngt_corpus, 'xml')\n",
    "        text_all = wsd_bs.find_all('sentence')\n",
    "        type2pos = {'j': 'ADJ', 'n': 'NOUN', 'r': 'ADV', 'v': 'VERB'}\n",
    "\n",
    "        adj_keys = get_adj_keys()\n",
    "        num = 0\n",
    "        for sent in tqdm(text_all[:]):\n",
    "            s = []\n",
    "            for word in sent.find_all('word'):\n",
    "                w = word['surface_form'].replace('_', ' ')\n",
    "                lemma = word['lemma'] if 'lemma' in word.attrs else word['surface_form'].replace('_', ' ')\n",
    "                pos = type2pos[word['pos'][0].lower()] if word['pos'][0].lower() in type2pos else word['pos']\n",
    "                key = word['wn30_key'].split(';')[0] if 'wn30_key' in word.attrs else -1\n",
    "                if key != -1 and key not in adj_keys and '%3:' in key:\n",
    "                    pos_string = key.split('%')[1][0]\n",
    "                    replace_string = '35'.replace(key.split('%')[1][0], '')\n",
    "                    key = key.replace('%' + pos_string + ':', '%' + replace_string + ':')\n",
    "                sense_inst = 'd0.s%d.t0' % num if key != -1 else -1\n",
    "                s.append((w, lemma, pos, sense_inst, key))\n",
    "            num += 1\n",
    "            sentences.append(s)\n",
    "\n",
    "    return sentences\n",
    "\n",
    "#normalize ids list, masks to whatever the passed in length is\n",
    "def normalize_length(ids, attn_mask, o_mask, max_len, pad_id):\n",
    "    if max_len == -1:\n",
    "        return ids, attn_mask, o_mask\n",
    "    else:\n",
    "        if len(ids) < max_len:\n",
    "            while len(ids) < max_len:\n",
    "                ids.append(torch.tensor([[pad_id]]))\n",
    "                attn_mask.append(0)\n",
    "                o_mask.append(-1)\n",
    "        else:\n",
    "            ids = ids[:max_len-1]+[ids[-1]]\n",
    "            attn_mask = attn_mask[:max_len]\n",
    "            o_mask = o_mask[:max_len]\n",
    "\n",
    "        assert len(ids) == max_len\n",
    "        assert len(attn_mask) == max_len\n",
    "        assert len(o_mask) == max_len\n",
    "\n",
    "        return ids, attn_mask, o_mask\n",
    "\n",
    "#filters down training dataset to (up to) k examples per sense \n",
    "#for few-shot learning of the model\n",
    "def filter_k_examples(data, k):\n",
    "    #shuffle data so we don't only get examples for (common) senses from beginning\n",
    "    random.shuffle(data)\n",
    "    #track number of times sense from data is used\n",
    "    sense_dict = {}\n",
    "    #store filtered data\n",
    "    filtered_data = []\n",
    "\n",
    "    example_count = 0\n",
    "    for sent in data:\n",
    "        filtered_sent = []\n",
    "        for form, lemma, pos, inst, sense in sent:\n",
    "            #treat unlabeled words normally\n",
    "            if sense == -1:\n",
    "                x  = (form, lemma, pos, inst, sense)\n",
    "            elif sense in sense_dict:\n",
    "                if sense_dict[sense] < k:\n",
    "                    #increment sense count and add example to filtered data\n",
    "                    sense_dict[sense] += 1\n",
    "                    x = (form, lemma, pos, inst, sense)\n",
    "                    example_count += 1\n",
    "                else: #if the data already has k examples of this sense\n",
    "                    #add example with no instance or sense label to data\n",
    "                    x = (form, lemma, pos, -1, -1)\n",
    "            else:\n",
    "                #add labeled example to filtered data and sense dict\n",
    "                sense_dict[sense] = 1\n",
    "                x = (form, lemma, pos, inst, sense)\n",
    "                example_count += 1\n",
    "            filtered_sent.append(x)\n",
    "        filtered_data.append(filtered_sent)\n",
    "\n",
    "    print(\"k={}, training on {} sense examples...\".format(k, example_count))\n",
    "\n",
    "    return filtered_data\n",
    "\n",
    "def tokenize_glosses(encoder_name, gloss_arr, tokenizer, max_len):\n",
    "    glosses = []\n",
    "    masks = []\n",
    "    for gloss_text in gloss_arr:\n",
    "        if 'xlm' in encoder_name:\n",
    "            g_ids = [torch.tensor([[x]]) for x in tokenizer.encode(gloss_text)]\n",
    "        else:\n",
    "            g_ids = [torch.tensor([[x]]) for x in\n",
    "                 tokenizer.encode(tokenizer.cls_token) + tokenizer.encode(gloss_text) + tokenizer.encode(\n",
    "                     tokenizer.sep_token)]\n",
    "        g_attn_mask = [1]*len(g_ids)\n",
    "        g_fake_mask = [-1]*len(g_ids)\n",
    "        if 'xlm' in encoder_name:\n",
    "            g_ids, g_attn_mask, _ = normalize_length(g_ids, g_attn_mask, g_fake_mask, max_len,\n",
    "                                                     pad_id=tokenizer.encode(tokenizer.pad_token)[1])\n",
    "        else:\n",
    "            g_ids, g_attn_mask, _ = normalize_length(g_ids, g_attn_mask, g_fake_mask, max_len,\n",
    "                                                 pad_id=tokenizer.encode(tokenizer.pad_token)[0])\n",
    "        g_ids = torch.cat(g_ids, dim=-1)\n",
    "        g_attn_mask = torch.tensor(g_attn_mask)\n",
    "        glosses.append(g_ids)\n",
    "        masks.append(g_attn_mask)\n",
    "\n",
    "    return glosses, masks\n",
    "\n",
    "\n",
    "\n",
    "def load_and_preprocess_glosses(data, tokenizer, wn_senses, max_len=-1):\n",
    "    sense_glosses = {}\n",
    "\n",
    "    for sent in data:\n",
    "        for _, lemma, pos, _, label in sent:\n",
    "            if label == -1:\n",
    "                continue  # ignore unlabeled words\n",
    "            else:\n",
    "                key = generate_key(lemma, pos)\n",
    "                if key not in sense_glosses:\n",
    "                    # get all sensekeys for the lemma/pos pair\n",
    "                    # get wordnet key\n",
    "                    sensekey_arr = wn_senses[key]\n",
    "                    if max_len <= 32:\n",
    "                        gloss_arr = [wn.lemma_from_key(s).synset().definition() for s in sensekey_arr]\n",
    "                        # print('gloss_arr:',gloss_arr)\n",
    "                    else:\n",
    "                        gloss_arr = [wn.lemma_from_key(s).synset().definition() + ' ' + '. '.join(\n",
    "                         wn.lemma_from_key(s).synset().examples()) for s in sensekey_arr]\n",
    "\n",
    "                    # preprocess glosses into tensors\n",
    "                    gloss_ids, gloss_masks = tokenize_glosses('bert-base', gloss_arr, tokenizer, max_len)\n",
    "                    gloss_ids = torch.cat(gloss_ids, dim=0)\n",
    "                    gloss_masks = torch.stack(gloss_masks, dim=0)\n",
    "                    sense_glosses[key] = (gloss_ids, gloss_masks, sensekey_arr)\n",
    "\n",
    "                # make sure that gold label is retrieved synset\n",
    "                assert label in sense_glosses[key][2]\n",
    "\n",
    "    return sense_glosses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_context(encoder_name, context_len, gloss_bsz, context_mode, tokenizer, text_data, gloss_dict=None, bsz=4, max_len=128):\n",
    "    if max_len == -1: assert bsz==1 #otherwise need max_length for padding\n",
    "\n",
    "    context_ids = []\n",
    "    context_attn_masks = []\n",
    "\n",
    "    example_keys = []\n",
    "\n",
    "    context_output_masks = []\n",
    "    instances = []\n",
    "    labels = []\n",
    "\n",
    "    #tensorize data\n",
    "    # print(tokenizer.encode(tokenizer.cls_token), tokenizer.encode(tokenizer.sep_token))\n",
    "    for sent in (text_data):\n",
    "        #cls token aka sos token, returns a list with index\n",
    "        if 'xlm' in encoder_name:\n",
    "            c_ids = [torch.tensor([tokenizer.encode(tokenizer.cls_token)[1:-1]])]\n",
    "        else:\n",
    "            c_ids = [torch.tensor([tokenizer.encode(tokenizer.cls_token)])]\n",
    "        o_masks = [-1]\n",
    "        sent_insts = []\n",
    "        sent_keys = []\n",
    "        sent_labels = []\n",
    "\n",
    "        #For each word in sentence...\n",
    "        key_len = []\n",
    "        for idx, (word, lemma, pos, inst, label) in enumerate(sent):\n",
    "            #tensorize word for context ids\n",
    "            if 'xlm' in encoder_name:\n",
    "                word_ids = [torch.tensor([[x]]) for x in tokenizer.encode(word.lower())[1:-1]]\n",
    "            else:\n",
    "                word_ids = [torch.tensor([[x]]) for x in tokenizer.encode(word.lower())]\n",
    "            c_ids.extend(word_ids)\n",
    "\n",
    "            #if word is labeled with WSD sense...\n",
    "            if label != -1:\n",
    "                #add word to bert output mask to be labeled\n",
    "                o_masks.extend([idx]*len(word_ids))\n",
    "                #track example instance id\n",
    "                sent_insts.append(inst)\n",
    "                #track example instance keys to get glosses\n",
    "                ex_key = generate_key(lemma, pos)\n",
    "                sent_keys.append(ex_key)\n",
    "                key_len.append(len(gloss_dict[ex_key][2]))\n",
    "                sent_labels.append(label)\n",
    "            else:\n",
    "                #mask out output of context encoder for WSD task (not labeled)\n",
    "                o_masks.extend([-1]*len(word_ids))\n",
    "\n",
    "            #break if we reach max len\n",
    "            if max_len != -1 and len(c_ids) >= (max_len-1):\n",
    "                break\n",
    "\n",
    "        if 'xlm' in encoder_name:\n",
    "            c_ids.append(torch.tensor([tokenizer.encode(tokenizer.sep_token)[1:-1]])) #aka eos token\n",
    "        else:\n",
    "            c_ids.append(torch.tensor([tokenizer.encode(tokenizer.sep_token)]))  # aka eos token\n",
    "        c_attn_mask = [1]*len(c_ids)\n",
    "        o_masks.append(-1)\n",
    "        assert len(c_ids) == len(o_masks)\n",
    "\n",
    "        #not including examples sentences with no annotated sense data\n",
    "        if len(sent_insts) > 0:\n",
    "            context_ids.append(c_ids)\n",
    "            context_attn_masks.append(c_attn_mask)\n",
    "            context_output_masks.append(o_masks)\n",
    "            example_keys.append(sent_keys)\n",
    "            instances.append(sent_insts)\n",
    "            labels.append(sent_labels)\n",
    "\n",
    "    #package data\n",
    "    context_dict = dict()\n",
    "\n",
    "    doc_id, doc_seg = [], []\n",
    "    for index, x in enumerate(instances):\n",
    "        inst = '.'.join(x[0].split('.')[:-2])\n",
    "        if inst not in doc_id:\n",
    "            doc_id.append(inst)\n",
    "            doc_seg.append(index)\n",
    "    doc_seg.append(len(instances))\n",
    "    new_context, new_attn_mask, new_out_mask = [], [], []\n",
    "\n",
    "    # 针对每个文档\n",
    "    for seg_index, seg_id in enumerate((doc_seg[:-1])):\n",
    "        ids_c = context_ids[seg_id: doc_seg[seg_index + 1]]\n",
    "        attn_masks_c = context_attn_masks[seg_id: doc_seg[seg_index + 1]]\n",
    "        output_masks_c = context_output_masks[seg_id: doc_seg[seg_index + 1]]\n",
    "        example_keys_c = example_keys[seg_id: doc_seg[seg_index + 1]]\n",
    "        instances_c = instances[seg_id: doc_seg[seg_index + 1]]\n",
    "        valid_instance = [i for i in instances_c[0] if i != -1][0]\n",
    "        sent_ids = ['.'.join(i[0].split('.')[:-1]) for i in instances_c]\n",
    "        if len(valid_instance.split('.')[0]) > 2:\n",
    "            # doc = [' '.join(examp) for examp in example_keys_c]\n",
    "            doc = [' '.join([i.split('+')[0] for i in examp if i.split('+')[1] in 'nvar']) for examp in example_keys_c]\n",
    "            vectorizer = TfidfVectorizer()\n",
    "            doc_mat = vectorizer.fit_transform(doc).toarray()\n",
    "            for sent_id, vec in enumerate(doc_mat):\n",
    "                scores = doc_mat[:, doc_mat[sent_id].nonzero()[0]].sum(1)\n",
    "                \n",
    "                #context_len控制了tf-idf筛选的数量\n",
    "                id_score = [j for j in\n",
    "                            sorted(zip([i for i in range(len(doc_mat))], scores), key=lambda x: x[1], reverse=True) if\n",
    "                            j[0] != sent_id][:context_len]\n",
    "                selected = [i[0] for i in id_score]\n",
    "                \n",
    "                #context_len控制了上下文窗口大小\n",
    "                window_id = [i for i in range(len(doc_mat))][\n",
    "                            max(sent_id - context_len, 0):sent_id + context_len + 1]\n",
    "                \n",
    "                pure_neighbor = [i for i in window_id if i != sent_id]\n",
    "                #\n",
    "                if context_mode == 'all':\n",
    "                    ids = sorted(set(selected + [sent_id] + pure_neighbor))\n",
    "                    # ids = selected + [sent_id] + pure_neighbor\n",
    "                elif context_mode == 'nonselect':\n",
    "                    ids = sorted(set([sent_id] + pure_neighbor))\n",
    "                    # ids = [sent_id] + pure_neighbor\n",
    "                elif context_mode == 'nonwindow':\n",
    "                    ids = sorted(set(selected + [sent_id]))\n",
    "                    # ids = selected + [sent_id]\n",
    "                else:\n",
    "                    ids = [sent_id]\n",
    "\n",
    "                # total_len = len(sum([ids_c[i]for i in ids], []))\n",
    "                # while total_len > 512:\n",
    "                #     distance_index = sorted([(abs(s_id-sent_id), s_id) for s_id in ids], reverse=True)\n",
    "                #     ids.remove(distance_index[0][1])\n",
    "                #     total_len = len(sum([ids_c[i] for i in ids], []))\n",
    "                    \n",
    "                if context_len > 0:\n",
    "                    new_context.append(sum([ids_c[i]for i in ids], []))\n",
    "                    new_attn_mask.append(sum([attn_masks_c[i] for i in ids], []))\n",
    "                    new_out_mask.append(\n",
    "                        sum([[-1] * len(output_masks_c[i]) if i != sent_id else output_masks_c[i] for i in ids], []))\n",
    "                    assert len(new_context[-1]) == len(new_attn_mask[-1]) == len(new_out_mask[-1])\n",
    "                else:\n",
    "                    new_context.append(ids_c[sent_id])\n",
    "                    new_attn_mask.append(attn_masks_c[sent_id])\n",
    "                    new_out_mask.append(output_masks_c[sent_id])\n",
    "                context_dict[sent_ids[sent_id]] = [sent_ids[i] for i in ids]\n",
    "        else:\n",
    "            new_context.extend(ids_c)\n",
    "            new_attn_mask.extend(attn_masks_c)\n",
    "            new_out_mask.extend(output_masks_c)\n",
    "\n",
    "            for sent_id in sent_ids:\n",
    "                context_dict[sent_id] = [sent_id]\n",
    "\n",
    "    assert len(context_ids) == len(new_context)\n",
    "\n",
    "    data = [list(i) for i in\n",
    "            list(zip(new_context, new_attn_mask, new_out_mask, example_keys, instances, labels))]\n",
    "\n",
    "    # print('Batching data with gloss length = {}...'.format(args.gloss_bsz))\n",
    "    batched_data = []\n",
    "    sent_index, current_list = [0], []\n",
    "    sent_senses = [sum([len(gloss_dict[ex_key][2]) for ex_key in sent[3]]) for sent in data]\n",
    "    for index, i in enumerate(sent_senses):\n",
    "        current_list.append(i)\n",
    "        if sum(current_list) > gloss_bsz:\n",
    "            sent_index.append(index)\n",
    "            current_list = current_list[-1:]\n",
    "    sent_index.append(len(sent_senses))\n",
    "\n",
    "    for index, data_index in enumerate(sent_index[:-1]):\n",
    "        b = data[data_index: sent_index[index + 1]]\n",
    "        max_len_b = max([len(x[1]) for x in b])\n",
    "        if context_len > 0:\n",
    "            max_len = max(max_len_b, max_len)\n",
    "        for b_index, sent in enumerate(b):\n",
    "            if 'xlm' in encoder_name:\n",
    "                b[b_index][0], b[b_index][1], b[b_index][2] = normalize_length(sent[0], sent[1], sent[2], max_len,\n",
    "                                                                           tokenizer.encode(tokenizer.pad_token)[1])\n",
    "            else:\n",
    "                b[b_index][0], b[b_index][1], b[b_index][2] = normalize_length(sent[0], sent[1], sent[2], max_len,\n",
    "                                                                           tokenizer.encode(tokenizer.pad_token)[0])\n",
    "\n",
    "        context_ids = torch.cat([torch.cat(x, dim=-1) for x, _, _, _, _, _ in b], dim=0)[:, :max_len_b]\n",
    "        context_attn_mask = torch.cat([torch.tensor(x).unsqueeze(dim=0) for _, x, _, _, _, _ in b], dim=0)[:,\n",
    "                            :max_len_b]\n",
    "        context_output_mask = torch.cat([torch.tensor(x).unsqueeze(dim=0) for _, _, x, _, _, _ in b], dim=0)[:,\n",
    "                              :max_len_b]\n",
    "        example_keys = []\n",
    "        for _, _, _, x, _, _ in b: example_keys.extend(x)\n",
    "        instances = []\n",
    "        for _, _, _, _, x, _ in b: instances.extend(x)\n",
    "        labels = []\n",
    "        for _, _, _, _, _, x in b: labels.extend(x)\n",
    "        batched_data.append(\n",
    "            (context_ids, context_attn_mask, context_output_mask, example_keys, instances, labels))\n",
    "    # context_dict包含每个句子的相关句集合，窗口大小为2，如句子7的相关句为[5,6,7,8,9]，同时加上tf-idf最大的top2\n",
    "    # batch是根据gloss_bsz划分的，每个batch中所有单词的义项总数不超过gloss_bsz\n",
    "    return batched_data, context_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This source code is licensed under the license found in the\n",
    "LICENSE file in the root directory of this source tree.\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import os\n",
    "\n",
    "def mask_logits(target, mask, logit=-1e30):\n",
    "    return target * mask + (1 - mask) * (logit)\n",
    "\n",
    "def load_projection(path):\n",
    "    proj_path = os.path.join(path, 'best_probe.ckpt')\n",
    "    with open(proj_path, 'rb') as f: proj_layer = torch.load(f)\n",
    "    return proj_layer\n",
    "\n",
    "class PretrainedClassifier(torch.nn.Module):\n",
    "    def __init__(self, num_labels, encoder_name, proj_ckpt_path):\n",
    "        super(PretrainedClassifier, self).__init__()\n",
    "\n",
    "        self.encoder, self.encoder_hdim = load_pretrained_model(encoder_name)\n",
    "\n",
    "        if proj_ckpt_path and len(proj_ckpt_path) > 0:\n",
    "            self.proj_layer = load_projection(proj_ckpt_path)\n",
    "            #assert to make sure correct dims\n",
    "            assert self.proj_layer.in_features == self.encoder_hdim\n",
    "            assert self.proj_layer.out_features == num_labels\n",
    "        else:\n",
    "            self.proj_layer = torch.nn.Linear(self.encoder_hdim, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, input_mask, example_mask):\n",
    "        output = self.encoder(input_ids, attention_mask=input_mask)[0]\n",
    "\n",
    "        example_arr = []\n",
    "        for i in range(output.size(0)):\n",
    "            example_arr.append(process_encoder_outputs(output[i], example_mask[i], as_tensor=True))\n",
    "        output = torch.cat(example_arr, dim=0)\n",
    "        output = self.proj_layer(output)\n",
    "        return output\n",
    "\n",
    "class GlossEncoder(torch.nn.Module):\n",
    "    def __init__(self, encoder_name, freeze_gloss, tied_encoder=None):\n",
    "        super(GlossEncoder, self).__init__()\n",
    "\n",
    "        #load pretrained model as base for context encoder and gloss encoder\n",
    "        if tied_encoder:\n",
    "            self.gloss_encoder = tied_encoder\n",
    "            _, self.gloss_hdim = load_pretrained_model(encoder_name)\n",
    "        else:\n",
    "            self.gloss_encoder, self.gloss_hdim = load_pretrained_model(encoder_name)\n",
    "        self.is_frozen = freeze_gloss\n",
    "\n",
    "    def forward(self, input_ids, attn_mask):\n",
    "        #encode gloss text\n",
    "        if self.is_frozen:\n",
    "            with torch.no_grad():\n",
    "                gloss_output = self.gloss_encoder(input_ids, attention_mask=attn_mask)[0]\n",
    "        else:\n",
    "            gloss_output = self.gloss_encoder(input_ids, attention_mask=attn_mask)[-1][-4:]\n",
    "\n",
    "        gloss_output = torch.cat([i.unsqueeze(0) for i in gloss_output], dim=0).mean(0)\n",
    "\n",
    "        #training model to put all sense information on CLS token\n",
    "        gloss_output = gloss_output[:,:,:].squeeze(dim=1)\n",
    "        return gloss_output\n",
    "\n",
    "class ContextEncoder(torch.nn.Module):\n",
    "    def __init__(self, encoder_name, freeze_context):\n",
    "        super(ContextEncoder, self).__init__()\n",
    "\n",
    "        #load pretrained model as base for context encoder and gloss encoder\n",
    "        self.context_encoder, self.context_hdim = load_pretrained_model(encoder_name)\n",
    "        self.is_frozen = freeze_context\n",
    "\n",
    "    def forward(self, input_ids, attn_mask, output_mask):\n",
    "        #encode context\n",
    "        if self.is_frozen:\n",
    "            with torch.no_grad():\n",
    "                context_output = self.context_encoder(input_ids, attention_mask=attn_mask)[0]\n",
    "        else:\n",
    "            context_output = self.context_encoder(input_ids, attention_mask=attn_mask)[-1][-4:]\n",
    "        context_output = torch.cat([i.unsqueeze(0) for i in context_output], dim=0).mean(0)\n",
    "        print('context_output1:', context_output.shape)\n",
    "        #average representations over target word(s)\n",
    "        example_arr = []\n",
    "        for i in range(context_output.size(0)):\n",
    "            example_arr.append(process_encoder_outputs(context_output[i], output_mask[i], as_tensor=True))\n",
    "        context_output = torch.cat(example_arr, dim=0)\n",
    "        print('context_output2:', context_output.shape)\n",
    "        return context_output\n",
    "\n",
    "class LinearAttention(nn.Module):\n",
    "    def __init__(self, in_dim=300, mem_dim=300):\n",
    "        # in dim, the dimension of query vector\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_dim, mem_dim)\n",
    "        self.fc = nn.Linear(in_dim, in_dim)\n",
    "        self.leakyrelu = nn.LeakyReLU(1e-2)\n",
    "        self.linear1 = nn.Linear(in_dim, mem_dim)\n",
    "        self.linear2 = nn.Linear(in_dim, mem_dim)\n",
    "        torch.nn.init.xavier_normal_(self.linear.weight.data)\n",
    "        torch.nn.init.xavier_normal_(self.linear1.weight.data)\n",
    "        torch.nn.init.xavier_normal_(self.linear2.weight.data)\n",
    "\n",
    "    def forward(self, feature, aspect_v, dmask, word='word'):\n",
    "        Q = self.linear(aspect_v.float())\n",
    "        Q = nn.functional.normalize(Q, dim=1)\n",
    "\n",
    "        attention_s = torch.mm(Q, Q.T)\n",
    "        attention_sk = mask_logits(attention_s, dmask, 0)\n",
    "        # print('attention_sk:', attention_sk.shape)\n",
    "\n",
    "        if 'word' in word:\n",
    "            new_feature = self.linear(feature.float())\n",
    "            new_feature = nn.functional.normalize(new_feature, dim=2)\n",
    "\n",
    "            feature_reshape = new_feature.reshape(new_feature.shape[0] * new_feature.shape[1], -1)\n",
    "            # print('feature_reshape:', feature_reshape.shape)\n",
    "            attention_ww = torch.mm(feature_reshape, feature_reshape.T)\n",
    "            attention_w = torch.stack(\n",
    "                torch.stack(attention_ww.split(new_feature.shape[1]), dim=0).mean(1).squeeze(1).split(new_feature.shape[1],\n",
    "                                                                                                      dim=1), dim=1).mean(2)\n",
    "            attention_wk = mask_logits(attention_w, dmask, 0)\n",
    "            # print('attention_wk:', attention_wk.shape)\n",
    "            \n",
    "            att_weight = attention_sk + attention_wk\n",
    "            # print('att_weight:', att_weight.shape)\n",
    "        else:\n",
    "            att_weight = attention_sk\n",
    "\n",
    "        att_weight[att_weight == 0] = -1e30\n",
    "        attention = F.softmax(att_weight, dim=1)\n",
    "\n",
    "        new_out = torch.mm(attention.float(), aspect_v.float())\n",
    "        # print('new_out:', new_out.shape)\n",
    "        return new_out\n",
    "\n",
    "class BiEncoderModel(torch.nn.Module):\n",
    "    def __init__(self, encoder_name, freeze_gloss=False, freeze_context=False, tie_encoders=False, num_heads=6):\n",
    "        super(BiEncoderModel, self).__init__()\n",
    "\n",
    "        #tying encoders for ablation\n",
    "        self.tie_encoders = tie_encoders\n",
    "\n",
    "        #load pretrained model as base for context encoder and gloss encoder\n",
    "        self.context_encoder = ContextEncoder(encoder_name, freeze_context)\n",
    "        if self.tie_encoders:\n",
    "            self.gloss_encoder = GlossEncoder(encoder_name, freeze_gloss, tied_encoder=self.context_encoder.context_encoder)\n",
    "        else:\n",
    "            self.gloss_encoder = GlossEncoder(encoder_name, freeze_gloss)\n",
    "        assert self.context_encoder.context_hdim == self.gloss_encoder.gloss_hdim\n",
    "        self.gat = [LinearAttention(self.gloss_encoder.gloss_hdim, self.gloss_encoder.gloss_hdim).cuda() for _ in\n",
    "                    range(num_heads)]\n",
    "\n",
    "    def context_forward(self, context_input, context_input_mask, context_example_mask):\n",
    "        return self.context_encoder.forward(context_input, context_input_mask, context_example_mask)\n",
    "\n",
    "    def gloss_forward(self, gloss_input, gloss_mask):\n",
    "        return self.gloss_encoder.forward(gloss_input, gloss_mask)\n",
    "\n",
    "    def gat_forward(self, gloss_input, gloss_mask, key_len_list, instances, pre_index, context_dict, senses=''):\n",
    "        gloss_out_all = self.gloss_encoder.forward(gloss_input, gloss_mask)\n",
    "        print('gloss_out_all:', gloss_out_all.shape)\n",
    "        if 'sense' in 'sense-pred':\n",
    "            key_len = sum(key_len_list, [])\n",
    "            # print('key_len:', len(key_len), key_len)\n",
    "            adjacency_mat = torch.zeros(sum(key_len), sum(key_len))\n",
    "            # print('adjacency_mat:', adjacency_mat.shape, adjacency_mat)\n",
    "            sense_index = [sum(key_len[:i]) for i in range(len(key_len))]\n",
    "            # print('sense_index:', sense_index)\n",
    "            if 'pred' in 'sense-pred':\n",
    "                p_index = [pre_index.get(inst, 0) for inst in instances]\n",
    "                sense_index = [sense_index[i] + p_index[i] for i in range(len(p_index))]\n",
    "                # print('p_index:', p_index)\n",
    "                # print('sense_index_new:', sense_index)\n",
    "            doc_sent = [('.'.join(i.split('.')[:-2]), int(i.split('.')[-2][1:]), '.'.join(i.split('.')[:-1])) for i in\n",
    "                        instances]\n",
    "            # print('doc_sent:', doc_sent)\n",
    "            adjacency_mat[:, sense_index] = 1\n",
    "            # print('adjacency_mat:', adjacency_mat.shape, adjacency_mat)\n",
    "            for i in range(len(instances)):\n",
    "                index = []\n",
    "                for s_index, sense in enumerate(sense_index):\n",
    "                    if True:\n",
    "                        if doc_sent[s_index][-1] not in context_dict[doc_sent[i][-1]]:\n",
    "                            index.extend([i for i in range(sum(key_len[:s_index]), sum(key_len[:s_index + 1]))])\n",
    "                    else:\n",
    "                        if len(doc_sent[s_index][0]) > 2:\n",
    "                            if doc_sent[s_index][0] != doc_sent[i][0] or abs(doc_sent[s_index][1] - doc_sent[i][1]) > 0:\n",
    "                                index.extend([i for i in range(sum(key_len[:s_index]), sum(key_len[:s_index + 1]))])\n",
    "                        elif abs(doc_sent[s_index][1] - doc_sent[i][1]) > 0:\n",
    "                            index.extend([i for i in range(sum(key_len[:s_index]), sum(key_len[:s_index + 1]))])\n",
    "                print(index)\n",
    "                adjacency_mat[sum(key_len[:i]): sum(key_len[:i + 1]), index] = 0\n",
    "\n",
    "            for k_index, j in enumerate(key_len):\n",
    "                start, end = sum(key_len[:k_index]), sum(key_len[:k_index + 1])\n",
    "                adjacency_mat[start: end, start: end] = 0\n",
    "            # print('!!!:',torch.nonzero(adjacency_mat[0]))\n",
    "\n",
    "            adjacency_mat_f = adjacency_mat + torch.eye(sum(key_len))\n",
    "            \n",
    "            # print('!!!:',torch.nonzero(adjacency_mat_f[0]))\n",
    "\n",
    "            att_out = [att.forward(gloss_out_all[:, 1:-1, :], gloss_out_all[:, 0, :], adjacency_mat_f.cuda(),\n",
    "                                   'word').unsqueeze(1) for att in self.gat]\n",
    "            att_out = torch.cat(att_out, dim=1)\n",
    "            # print('att_out1:', att_out.shape)\n",
    "            att_out = att_out.mean(dim=1)  # (N, D)min(31, gloss_out_all.shape[1]-1)\n",
    "            print('att_out:', att_out.shape)\n",
    "            assert len(gloss_out_all) == len(att_out)\n",
    "            return att_out\n",
    "        else:\n",
    "            return gloss_out_all[:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pen%1:06:00::',\n",
       " 'pen%1:06:01::',\n",
       " 'pen%1:06:03::',\n",
       " 'pen%1:06:02::',\n",
       " 'pen%1:05:00::']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn_path = os.path.join('./WSD_Evaluation_Framework/', 'Data_Validation/candidatesWN30.txt')\n",
    "# 获取一个字典，key是lemma+pos，value是该词的所有senses，senses表示方法为wordnet_key\n",
    "wn_senses =  load_wn_senses(wn_path)\n",
    "wn_senses[\"pen+n\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155287"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wn_senses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data('./WSD_Evaluation_Framework/Training_Corpora/SemCor', 'semcor', 1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_name = 'bert-base'\n",
    "tokenizer = load_tokenizer(encoder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BiEncoderModel('bert-base').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gloss_dict = load_and_preprocess_glosses(data, tokenizer, wn_senses, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('How', 'how', 'ADV', -1, -1),\n",
       " ('long', 'long', 'ADJ', 'd000.s000.t000', 'long%3:00:02::'),\n",
       " ('has', 'have', 'VERB', -1, -1),\n",
       " ('it', 'it', 'PRON', -1, -1),\n",
       " ('been', 'be', 'VERB', 'd000.s000.t001', 'be%2:42:03::'),\n",
       " ('since', 'since', 'ADP', -1, -1),\n",
       " ('you', 'you', 'PRON', -1, -1),\n",
       " ('reviewed', 'review', 'VERB', 'd000.s000.t002', 'review%2:31:00::'),\n",
       " ('the', 'the', 'DET', -1, -1),\n",
       " ('objectives', 'objective', 'NOUN', 'd000.s000.t003', 'objective%1:09:00::'),\n",
       " ('of', 'of', 'ADP', -1, -1),\n",
       " ('your', 'you', 'PRON', -1, -1),\n",
       " ('benefit', 'benefit', 'NOUN', 'd000.s000.t004', 'benefit%1:21:00::'),\n",
       " ('and', 'and', 'CONJ', -1, -1),\n",
       " ('service', 'service', 'NOUN', 'd000.s000.t005', 'service%1:04:07::'),\n",
       " ('program', 'program', 'NOUN', 'd000.s000.t006', 'program%1:09:01::'),\n",
       " ('?', '?', '.', -1, -1)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = preprocess_context(encoder_name, 4, 400, 'all', tokenizer, data, gloss_dict, bsz=4, max_len=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 8, 9, 8)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b['d000.s000']),len(b['d000.s001']),len(b['d000.s002']),len(b['d000.s003'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d000.s000',\n",
       " 'd000.s001',\n",
       " 'd000.s002',\n",
       " 'd000.s003',\n",
       " 'd000.s004',\n",
       " 'd000.s034',\n",
       " 'd000.s064',\n",
       " 'd000.s065',\n",
       " 'd000.s072']"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b['d000.s000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 512])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_ids, context_attn_mask, context_output_mask, example_keys, instances, labels = a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "恢复的原文: [CLS] how long has it been since you reviewed the objectives of your benefit and service program ? [SEP] [CLS] have you permitted it to become a giveaway program rather than one that has the goal of improved employee morale and , consequently , increased productivity ? [SEP] [CLS] what effort do you make to assess results of your program ? [SEP] [CLS] do you measure its relation to reduced absenteeism , turnover , accidents , and grievances , and to improved quality and output ? [SEP] [CLS] have you set specific objectives for your employee publication ? [SEP] [CLS] are your expenses in this area commensurate with the number of employees who benefit from your program ? [SEP] [CLS] if you have an annual or regular physical examination program , is it worth what it is costing you ? [SEP] [CLS] consider what you can afford to spend and what your goals are before setting up or revamping your employee benefit program . [SEP] [CLS] these factors can make the difference between waste and efficiency in any benefit program . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "恢复的原文: [CLS] how long has it been since you reviewed the objectives of your benefit and service program ? [SEP] [CLS] have you permitted it to become a giveaway program rather than one that has the goal of improved employee morale and , consequently , increased productivity ? [SEP] [CLS] what effort do you make to assess results of your program ? [SEP] [CLS] do you measure its relation to reduced absenteeism , turnover , accidents , and grievances , and to improved quality and output ? [SEP] [CLS] have you set specific objectives for your employee publication ? [SEP] [CLS] is it reaching these goals ? [SEP] [CLS] are your expenses in this area commensurate with the number of employees who benefit from your program ? [SEP] [CLS] if you have an annual or regular physical examination program , is it worth what it is costing you ? [SEP] [CLS] consider what you can afford to spend and what your goals are before setting up or revamping your employee benefit program . [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "tokenized_tensor = context_ids[0].tolist()\n",
    "tokenized_tensor1 = context_ids[1].tolist()\n",
    "# 使用BertTokenizer将tokenized的tensor还原为token\n",
    "restored_tokens = tokenizer.convert_ids_to_tokens(tokenized_tensor)\n",
    "restored_tokens1 = tokenizer.convert_ids_to_tokens(tokenized_tensor1)\n",
    "# 将token还原为原始文本\n",
    "restored_text = tokenizer.convert_tokens_to_string(restored_tokens)\n",
    "restored_text1 = tokenizer.convert_tokens_to_string(restored_tokens1)\n",
    "\n",
    "# 打印恢复的原文\n",
    "print(\"恢复的原文:\", restored_text)\n",
    "print(\"恢复的原文:\", restored_text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  101,  1293,  1263,  1144,  1122,  1151,  1290,  1128,  7815,  1103,\n",
       "         11350,  1104,  1240,  5257,  1105,  1555,  1788,   136,   102,   101,\n",
       "          1138,  1128,  7485,  1122,  1106,  1561,   170,  1660,  7138,  1788,\n",
       "          1897,  1190,  1141,  1115,  1144,  1103,  2273,  1104,  4725,  7775,\n",
       "         22407,  1105,   117, 14007,   117,  2569, 18222,   136,   102,   101,\n",
       "          1184,  3098,  1202,  1128,  1294,  1106, 15187,  2686,  1104,  1240,\n",
       "          1788,   136,   102,   101,  1202,  1128,  4929,  1157,  6796,  1106,\n",
       "          3549, 10040,  3051,  1863,   117, 23804,   117, 14705,   117,  1105,\n",
       "           176,  5997, 24043,  1116,   117,  1105,  1106,  4725,  3068,  1105,\n",
       "          5964,   136,   102,   101,  1138,  1128,  1383,  2747, 11350,  1111,\n",
       "          1240,  7775,  4128,   136,   102,   101,  1110,  1122,  3634,  1292,\n",
       "          2513,   136,   102,   101,  1132,  1240, 11928,  1107,  1142,  1298,\n",
       "          3254,  2354,  6385,  5498,  1114,  1103,  1295,  1104,  4570,  1150,\n",
       "          5257,  1121,  1240,  1788,   136,   102,   101,  1191,  1128,  1138,\n",
       "          1126,  2683,  1137,  2366,  2952,  8179,  1788,   117,  1110,  1122,\n",
       "          3869,  1184,  1122,  1110, 25522,  1128,   136,   102,   101,  4615,\n",
       "          1184,  1128,  1169,  8658,  1106,  4511,  1105,  1184,  1240,  2513,\n",
       "          1132,  1196,  3545,  1146,  1137,  1231,  2497,  8223,  1158,  1240,\n",
       "          7775,  5257,  1788,   119,   102,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        device='cuda:0'),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        device='cuda:0'),\n",
       " tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1,  2, -1, -1,  5, -1,  7,  7,  8,  9, -1, -1, -1, 13, -1,\n",
       "         15, -1, 17, 18, 19, -1, -1, 22, -1, 24, 25, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "         -1, -1, -1, -1, -1, -1, -1, -1]))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_ids[1],context_attn_mask[1], context_output_mask[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d000.s000': ['d000.s000',\n",
       "  'd000.s001',\n",
       "  'd000.s002',\n",
       "  'd000.s003',\n",
       "  'd000.s004',\n",
       "  'd000.s034',\n",
       "  'd000.s064',\n",
       "  'd000.s065',\n",
       "  'd000.s072'],\n",
       " 'd000.s001': ['d000.s000',\n",
       "  'd000.s001',\n",
       "  'd000.s002',\n",
       "  'd000.s003',\n",
       "  'd000.s004',\n",
       "  'd000.s005',\n",
       "  'd000.s034',\n",
       "  'd000.s064',\n",
       "  'd000.s065'],\n",
       " 'd000.s002': ['d000.s000',\n",
       "  'd000.s001',\n",
       "  'd000.s002',\n",
       "  'd000.s003',\n",
       "  'd000.s004',\n",
       "  'd000.s005',\n",
       "  'd000.s006',\n",
       "  'd000.s034',\n",
       "  'd000.s042',\n",
       "  'd000.s056',\n",
       "  'd000.s072'],\n",
       " 'd000.s003': ['d000.s000',\n",
       "  'd000.s001',\n",
       "  'd000.s002',\n",
       "  'd000.s003',\n",
       "  'd000.s004',\n",
       "  'd000.s005',\n",
       "  'd000.s006',\n",
       "  'd000.s007',\n",
       "  'd000.s126'],\n",
       " 'd000.s004': ['d000.s000',\n",
       "  'd000.s001',\n",
       "  'd000.s002',\n",
       "  'd000.s003',\n",
       "  'd000.s004',\n",
       "  'd000.s005',\n",
       "  'd000.s006',\n",
       "  'd000.s007',\n",
       "  'd000.s008',\n",
       "  'd000.s011',\n",
       "  'd000.s014',\n",
       "  'd000.s080'],\n",
       " 'd000.s005': ['d000.s000',\n",
       "  'd000.s001',\n",
       "  'd000.s002',\n",
       "  'd000.s003',\n",
       "  'd000.s004',\n",
       "  'd000.s005',\n",
       "  'd000.s006',\n",
       "  'd000.s007',\n",
       "  'd000.s008',\n",
       "  'd000.s009',\n",
       "  'd000.s065'],\n",
       " 'd000.s006': ['d000.s002',\n",
       "  'd000.s003',\n",
       "  'd000.s004',\n",
       "  'd000.s005',\n",
       "  'd000.s006',\n",
       "  'd000.s007',\n",
       "  'd000.s008',\n",
       "  'd000.s009',\n",
       "  'd000.s010',\n",
       "  'd000.s023',\n",
       "  'd000.s068',\n",
       "  'd000.s070',\n",
       "  'd000.s071'],\n",
       " 'd000.s007': ['d000.s003',\n",
       "  'd000.s004',\n",
       "  'd000.s005',\n",
       "  'd000.s006',\n",
       "  'd000.s007',\n",
       "  'd000.s008',\n",
       "  'd000.s009',\n",
       "  'd000.s010',\n",
       "  'd000.s011',\n",
       "  'd000.s089',\n",
       "  'd000.s124',\n",
       "  'd000.s129',\n",
       "  'd000.s133'],\n",
       " 'd000.s008': ['d000.s004',\n",
       "  'd000.s005',\n",
       "  'd000.s006',\n",
       "  'd000.s007',\n",
       "  'd000.s008',\n",
       "  'd000.s009',\n",
       "  'd000.s010',\n",
       "  'd000.s011',\n",
       "  'd000.s012',\n",
       "  'd000.s023',\n",
       "  'd000.s047',\n",
       "  'd000.s067',\n",
       "  'd000.s120'],\n",
       " 'd000.s009': ['d000.s005',\n",
       "  'd000.s006',\n",
       "  'd000.s007',\n",
       "  'd000.s008',\n",
       "  'd000.s009',\n",
       "  'd000.s010',\n",
       "  'd000.s011',\n",
       "  'd000.s012',\n",
       "  'd000.s013',\n",
       "  'd000.s014',\n",
       "  'd000.s015',\n",
       "  'd000.s079'],\n",
       " 'd000.s010': ['d000.s000',\n",
       "  'd000.s006',\n",
       "  'd000.s007',\n",
       "  'd000.s008',\n",
       "  'd000.s009',\n",
       "  'd000.s010',\n",
       "  'd000.s011',\n",
       "  'd000.s012',\n",
       "  'd000.s013',\n",
       "  'd000.s014',\n",
       "  'd000.s063'],\n",
       " 'd000.s011': ['d000.s004',\n",
       "  'd000.s007',\n",
       "  'd000.s008',\n",
       "  'd000.s009',\n",
       "  'd000.s010',\n",
       "  'd000.s011',\n",
       "  'd000.s012',\n",
       "  'd000.s013',\n",
       "  'd000.s014',\n",
       "  'd000.s015',\n",
       "  'd000.s059',\n",
       "  'd000.s068',\n",
       "  'd000.s095'],\n",
       " 'd000.s012': ['d000.s008',\n",
       "  'd000.s009',\n",
       "  'd000.s010',\n",
       "  'd000.s011',\n",
       "  'd000.s012',\n",
       "  'd000.s013',\n",
       "  'd000.s014',\n",
       "  'd000.s015',\n",
       "  'd000.s016',\n",
       "  'd000.s107',\n",
       "  'd000.s115',\n",
       "  'd000.s129',\n",
       "  'd000.s134'],\n",
       " 'd000.s013': ['d000.s009',\n",
       "  'd000.s010',\n",
       "  'd000.s011',\n",
       "  'd000.s012',\n",
       "  'd000.s013',\n",
       "  'd000.s014',\n",
       "  'd000.s015',\n",
       "  'd000.s016',\n",
       "  'd000.s017',\n",
       "  'd000.s036',\n",
       "  'd000.s037',\n",
       "  'd000.s065',\n",
       "  'd000.s082'],\n",
       " 'd000.s014': ['d000.s010',\n",
       "  'd000.s011',\n",
       "  'd000.s012',\n",
       "  'd000.s013',\n",
       "  'd000.s014',\n",
       "  'd000.s015',\n",
       "  'd000.s016',\n",
       "  'd000.s017',\n",
       "  'd000.s018',\n",
       "  'd000.s034',\n",
       "  'd000.s075',\n",
       "  'd000.s078',\n",
       "  'd000.s094'],\n",
       " 'd000.s015': ['d000.s009',\n",
       "  'd000.s011',\n",
       "  'd000.s012',\n",
       "  'd000.s013',\n",
       "  'd000.s014',\n",
       "  'd000.s015',\n",
       "  'd000.s016',\n",
       "  'd000.s017',\n",
       "  'd000.s018',\n",
       "  'd000.s019',\n",
       "  'd000.s075',\n",
       "  'd000.s079'],\n",
       " 'd000.s016': ['d000.s012',\n",
       "  'd000.s013',\n",
       "  'd000.s014',\n",
       "  'd000.s015',\n",
       "  'd000.s016',\n",
       "  'd000.s017',\n",
       "  'd000.s018',\n",
       "  'd000.s019',\n",
       "  'd000.s020',\n",
       "  'd000.s036',\n",
       "  'd000.s059',\n",
       "  'd000.s093'],\n",
       " 'd000.s017': ['d000.s013',\n",
       "  'd000.s014',\n",
       "  'd000.s015',\n",
       "  'd000.s016',\n",
       "  'd000.s017',\n",
       "  'd000.s018',\n",
       "  'd000.s019',\n",
       "  'd000.s020',\n",
       "  'd000.s021',\n",
       "  'd000.s028',\n",
       "  'd000.s085',\n",
       "  'd000.s086',\n",
       "  'd000.s089'],\n",
       " 'd000.s018': ['d000.s014',\n",
       "  'd000.s015',\n",
       "  'd000.s016',\n",
       "  'd000.s017',\n",
       "  'd000.s018',\n",
       "  'd000.s019',\n",
       "  'd000.s020',\n",
       "  'd000.s021',\n",
       "  'd000.s022',\n",
       "  'd000.s028',\n",
       "  'd000.s031',\n",
       "  'd000.s086'],\n",
       " 'd000.s019': ['d000.s015',\n",
       "  'd000.s016',\n",
       "  'd000.s017',\n",
       "  'd000.s018',\n",
       "  'd000.s019',\n",
       "  'd000.s020',\n",
       "  'd000.s021',\n",
       "  'd000.s022',\n",
       "  'd000.s023',\n",
       "  'd000.s034',\n",
       "  'd000.s036',\n",
       "  'd000.s065',\n",
       "  'd000.s078'],\n",
       " 'd000.s020': ['d000.s016',\n",
       "  'd000.s017',\n",
       "  'd000.s018',\n",
       "  'd000.s019',\n",
       "  'd000.s020',\n",
       "  'd000.s021',\n",
       "  'd000.s022',\n",
       "  'd000.s023',\n",
       "  'd000.s024',\n",
       "  'd000.s095',\n",
       "  'd000.s107',\n",
       "  'd000.s115'],\n",
       " 'd000.s021': ['d000.s017',\n",
       "  'd000.s018',\n",
       "  'd000.s019',\n",
       "  'd000.s020',\n",
       "  'd000.s021',\n",
       "  'd000.s022',\n",
       "  'd000.s023',\n",
       "  'd000.s024',\n",
       "  'd000.s025',\n",
       "  'd000.s031',\n",
       "  'd000.s034',\n",
       "  'd000.s093'],\n",
       " 'd000.s022': ['d000.s018',\n",
       "  'd000.s019',\n",
       "  'd000.s020',\n",
       "  'd000.s021',\n",
       "  'd000.s022',\n",
       "  'd000.s023',\n",
       "  'd000.s024',\n",
       "  'd000.s025',\n",
       "  'd000.s026',\n",
       "  'd000.s029',\n",
       "  'd000.s115',\n",
       "  'd000.s122'],\n",
       " 'd000.s023': ['d000.s008',\n",
       "  'd000.s019',\n",
       "  'd000.s020',\n",
       "  'd000.s021',\n",
       "  'd000.s022',\n",
       "  'd000.s023',\n",
       "  'd000.s024',\n",
       "  'd000.s025',\n",
       "  'd000.s026',\n",
       "  'd000.s027',\n",
       "  'd000.s029',\n",
       "  'd000.s050',\n",
       "  'd000.s067'],\n",
       " 'd000.s024': ['d000.s020',\n",
       "  'd000.s021',\n",
       "  'd000.s022',\n",
       "  'd000.s023',\n",
       "  'd000.s024',\n",
       "  'd000.s025',\n",
       "  'd000.s026',\n",
       "  'd000.s027',\n",
       "  'd000.s028',\n",
       "  'd000.s029',\n",
       "  'd000.s050',\n",
       "  'd000.s067'],\n",
       " 'd000.s025': ['d000.s021',\n",
       "  'd000.s022',\n",
       "  'd000.s023',\n",
       "  'd000.s024',\n",
       "  'd000.s025',\n",
       "  'd000.s026',\n",
       "  'd000.s027',\n",
       "  'd000.s028',\n",
       "  'd000.s029',\n",
       "  'd000.s034',\n",
       "  'd000.s068',\n",
       "  'd000.s106',\n",
       "  'd000.s121'],\n",
       " 'd000.s026': ['d000.s022',\n",
       "  'd000.s023',\n",
       "  'd000.s024',\n",
       "  'd000.s025',\n",
       "  'd000.s026',\n",
       "  'd000.s027',\n",
       "  'd000.s028',\n",
       "  'd000.s029',\n",
       "  'd000.s030',\n",
       "  'd000.s034',\n",
       "  'd000.s057',\n",
       "  'd000.s121',\n",
       "  'd000.s124'],\n",
       " 'd000.s027': ['d000.s023',\n",
       "  'd000.s024',\n",
       "  'd000.s025',\n",
       "  'd000.s026',\n",
       "  'd000.s027',\n",
       "  'd000.s028',\n",
       "  'd000.s029',\n",
       "  'd000.s030',\n",
       "  'd000.s031',\n",
       "  'd000.s122',\n",
       "  'd000.s124'],\n",
       " 'd000.s028': ['d000.s017',\n",
       "  'd000.s018',\n",
       "  'd000.s024',\n",
       "  'd000.s025',\n",
       "  'd000.s026',\n",
       "  'd000.s027',\n",
       "  'd000.s028',\n",
       "  'd000.s029',\n",
       "  'd000.s030',\n",
       "  'd000.s031',\n",
       "  'd000.s032',\n",
       "  'd000.s129'],\n",
       " 'd000.s029': ['d000.s023',\n",
       "  'd000.s025',\n",
       "  'd000.s026',\n",
       "  'd000.s027',\n",
       "  'd000.s028',\n",
       "  'd000.s029',\n",
       "  'd000.s030',\n",
       "  'd000.s031',\n",
       "  'd000.s032',\n",
       "  'd000.s033',\n",
       "  'd000.s050',\n",
       "  'd000.s060',\n",
       "  'd000.s108'],\n",
       " 'd000.s030': ['d000.s026',\n",
       "  'd000.s027',\n",
       "  'd000.s028',\n",
       "  'd000.s029',\n",
       "  'd000.s030',\n",
       "  'd000.s031',\n",
       "  'd000.s032',\n",
       "  'd000.s033',\n",
       "  'd000.s034',\n",
       "  'd000.s059',\n",
       "  'd000.s119'],\n",
       " 'd000.s031': ['d000.s018',\n",
       "  'd000.s027',\n",
       "  'd000.s028',\n",
       "  'd000.s029',\n",
       "  'd000.s030',\n",
       "  'd000.s031',\n",
       "  'd000.s032',\n",
       "  'd000.s033',\n",
       "  'd000.s034',\n",
       "  'd000.s035',\n",
       "  'd000.s087',\n",
       "  'd000.s089'],\n",
       " 'd000.s032': ['d000.s028',\n",
       "  'd000.s029',\n",
       "  'd000.s030',\n",
       "  'd000.s031',\n",
       "  'd000.s032',\n",
       "  'd000.s033',\n",
       "  'd000.s034',\n",
       "  'd000.s035',\n",
       "  'd000.s036',\n",
       "  'd000.s037',\n",
       "  'd000.s067',\n",
       "  'd000.s118'],\n",
       " 'd000.s033': ['d000.s029',\n",
       "  'd000.s030',\n",
       "  'd000.s031',\n",
       "  'd000.s032',\n",
       "  'd000.s033',\n",
       "  'd000.s034',\n",
       "  'd000.s035',\n",
       "  'd000.s036',\n",
       "  'd000.s037',\n",
       "  'd000.s042',\n",
       "  'd000.s048',\n",
       "  'd000.s052',\n",
       "  'd000.s124'],\n",
       " 'd000.s034': ['d000.s000',\n",
       "  'd000.s014',\n",
       "  'd000.s030',\n",
       "  'd000.s031',\n",
       "  'd000.s032',\n",
       "  'd000.s033',\n",
       "  'd000.s034',\n",
       "  'd000.s035',\n",
       "  'd000.s036',\n",
       "  'd000.s037',\n",
       "  'd000.s038',\n",
       "  'd000.s065',\n",
       "  'd000.s075'],\n",
       " 'd000.s035': ['d000.s002',\n",
       "  'd000.s013',\n",
       "  'd000.s031',\n",
       "  'd000.s032',\n",
       "  'd000.s033',\n",
       "  'd000.s034',\n",
       "  'd000.s035',\n",
       "  'd000.s036',\n",
       "  'd000.s037',\n",
       "  'd000.s038',\n",
       "  'd000.s039',\n",
       "  'd000.s042'],\n",
       " 'd000.s036': ['d000.s019',\n",
       "  'd000.s032',\n",
       "  'd000.s033',\n",
       "  'd000.s034',\n",
       "  'd000.s035',\n",
       "  'd000.s036',\n",
       "  'd000.s037',\n",
       "  'd000.s038',\n",
       "  'd000.s039',\n",
       "  'd000.s040',\n",
       "  'd000.s059',\n",
       "  'd000.s111'],\n",
       " 'd000.s037': ['d000.s013',\n",
       "  'd000.s026',\n",
       "  'd000.s032',\n",
       "  'd000.s033',\n",
       "  'd000.s034',\n",
       "  'd000.s035',\n",
       "  'd000.s036',\n",
       "  'd000.s037',\n",
       "  'd000.s038',\n",
       "  'd000.s039',\n",
       "  'd000.s040',\n",
       "  'd000.s041',\n",
       "  'd000.s065'],\n",
       " 'd000.s038': ['d000.s009',\n",
       "  'd000.s034',\n",
       "  'd000.s035',\n",
       "  'd000.s036',\n",
       "  'd000.s037',\n",
       "  'd000.s038',\n",
       "  'd000.s039',\n",
       "  'd000.s040',\n",
       "  'd000.s041',\n",
       "  'd000.s042',\n",
       "  'd000.s053'],\n",
       " 'd000.s039': ['d000.s035',\n",
       "  'd000.s036',\n",
       "  'd000.s037',\n",
       "  'd000.s038',\n",
       "  'd000.s039',\n",
       "  'd000.s040',\n",
       "  'd000.s041',\n",
       "  'd000.s042',\n",
       "  'd000.s043',\n",
       "  'd000.s053',\n",
       "  'd000.s066',\n",
       "  'd000.s128'],\n",
       " 'd000.s040': ['d000.s013',\n",
       "  'd000.s014',\n",
       "  'd000.s036',\n",
       "  'd000.s037',\n",
       "  'd000.s038',\n",
       "  'd000.s039',\n",
       "  'd000.s040',\n",
       "  'd000.s041',\n",
       "  'd000.s042',\n",
       "  'd000.s043',\n",
       "  'd000.s044',\n",
       "  'd000.s094'],\n",
       " 'd000.s041': ['d000.s000',\n",
       "  'd000.s001',\n",
       "  'd000.s037',\n",
       "  'd000.s038',\n",
       "  'd000.s039',\n",
       "  'd000.s040',\n",
       "  'd000.s041',\n",
       "  'd000.s042',\n",
       "  'd000.s043',\n",
       "  'd000.s044',\n",
       "  'd000.s045',\n",
       "  'd000.s121'],\n",
       " 'd000.s042': ['d000.s029',\n",
       "  'd000.s033',\n",
       "  'd000.s038',\n",
       "  'd000.s039',\n",
       "  'd000.s040',\n",
       "  'd000.s041',\n",
       "  'd000.s042',\n",
       "  'd000.s043',\n",
       "  'd000.s044',\n",
       "  'd000.s045',\n",
       "  'd000.s046',\n",
       "  'd000.s115',\n",
       "  'd000.s124'],\n",
       " 'd000.s043': ['d000.s017',\n",
       "  'd000.s028',\n",
       "  'd000.s039',\n",
       "  'd000.s040',\n",
       "  'd000.s041',\n",
       "  'd000.s042',\n",
       "  'd000.s043',\n",
       "  'd000.s044',\n",
       "  'd000.s045',\n",
       "  'd000.s046',\n",
       "  'd000.s047',\n",
       "  'd000.s085'],\n",
       " 'd000.s044': ['d000.s007',\n",
       "  'd000.s026',\n",
       "  'd000.s040',\n",
       "  'd000.s041',\n",
       "  'd000.s042',\n",
       "  'd000.s043',\n",
       "  'd000.s044',\n",
       "  'd000.s045',\n",
       "  'd000.s046',\n",
       "  'd000.s047',\n",
       "  'd000.s048',\n",
       "  'd000.s089',\n",
       "  'd000.s124'],\n",
       " 'd000.s045': ['d000.s019',\n",
       "  'd000.s041',\n",
       "  'd000.s042',\n",
       "  'd000.s043',\n",
       "  'd000.s044',\n",
       "  'd000.s045',\n",
       "  'd000.s046',\n",
       "  'd000.s047',\n",
       "  'd000.s048',\n",
       "  'd000.s049',\n",
       "  'd000.s059',\n",
       "  'd000.s066'],\n",
       " 'd000.s046': ['d000.s026',\n",
       "  'd000.s042',\n",
       "  'd000.s043',\n",
       "  'd000.s044',\n",
       "  'd000.s045',\n",
       "  'd000.s046',\n",
       "  'd000.s047',\n",
       "  'd000.s048',\n",
       "  'd000.s049',\n",
       "  'd000.s050',\n",
       "  'd000.s061',\n",
       "  'd000.s066'],\n",
       " 'd000.s047': ['d000.s008',\n",
       "  'd000.s043',\n",
       "  'd000.s044',\n",
       "  'd000.s045',\n",
       "  'd000.s046',\n",
       "  'd000.s047',\n",
       "  'd000.s048',\n",
       "  'd000.s049',\n",
       "  'd000.s050',\n",
       "  'd000.s051',\n",
       "  'd000.s089'],\n",
       " 'd000.s048': ['d000.s044',\n",
       "  'd000.s045',\n",
       "  'd000.s046',\n",
       "  'd000.s047',\n",
       "  'd000.s048',\n",
       "  'd000.s049',\n",
       "  'd000.s050',\n",
       "  'd000.s051',\n",
       "  'd000.s052',\n",
       "  'd000.s068',\n",
       "  'd000.s071',\n",
       "  'd000.s081'],\n",
       " 'd000.s049': ['d000.s000',\n",
       "  'd000.s001',\n",
       "  'd000.s002',\n",
       "  'd000.s003',\n",
       "  'd000.s045',\n",
       "  'd000.s046',\n",
       "  'd000.s047',\n",
       "  'd000.s048',\n",
       "  'd000.s049',\n",
       "  'd000.s050',\n",
       "  'd000.s051',\n",
       "  'd000.s052',\n",
       "  'd000.s053'],\n",
       " 'd000.s050': ['d000.s023',\n",
       "  'd000.s029',\n",
       "  'd000.s046',\n",
       "  'd000.s047',\n",
       "  'd000.s048',\n",
       "  'd000.s049',\n",
       "  'd000.s050',\n",
       "  'd000.s051',\n",
       "  'd000.s052',\n",
       "  'd000.s053',\n",
       "  'd000.s054',\n",
       "  'd000.s058',\n",
       "  'd000.s060'],\n",
       " 'd000.s051': ['d000.s047',\n",
       "  'd000.s048',\n",
       "  'd000.s049',\n",
       "  'd000.s050',\n",
       "  'd000.s051',\n",
       "  'd000.s052',\n",
       "  'd000.s053',\n",
       "  'd000.s054',\n",
       "  'd000.s055',\n",
       "  'd000.s122',\n",
       "  'd000.s133'],\n",
       " 'd000.s052': ['d000.s026',\n",
       "  'd000.s034',\n",
       "  'd000.s048',\n",
       "  'd000.s049',\n",
       "  'd000.s050',\n",
       "  'd000.s051',\n",
       "  'd000.s052',\n",
       "  'd000.s053',\n",
       "  'd000.s054',\n",
       "  'd000.s055',\n",
       "  'd000.s056',\n",
       "  'd000.s135'],\n",
       " 'd000.s053': ['d000.s049',\n",
       "  'd000.s050',\n",
       "  'd000.s051',\n",
       "  'd000.s052',\n",
       "  'd000.s053',\n",
       "  'd000.s054',\n",
       "  'd000.s055',\n",
       "  'd000.s056',\n",
       "  'd000.s057',\n",
       "  'd000.s121',\n",
       "  'd000.s128',\n",
       "  'd000.s133'],\n",
       " 'd000.s054': ['d000.s050',\n",
       "  'd000.s051',\n",
       "  'd000.s052',\n",
       "  'd000.s053',\n",
       "  'd000.s054',\n",
       "  'd000.s055',\n",
       "  'd000.s056',\n",
       "  'd000.s057',\n",
       "  'd000.s058',\n",
       "  'd000.s131',\n",
       "  'd000.s133'],\n",
       " 'd000.s055': ['d000.s017',\n",
       "  'd000.s028',\n",
       "  'd000.s036',\n",
       "  'd000.s051',\n",
       "  'd000.s052',\n",
       "  'd000.s053',\n",
       "  'd000.s054',\n",
       "  'd000.s055',\n",
       "  'd000.s056',\n",
       "  'd000.s057',\n",
       "  'd000.s058',\n",
       "  'd000.s059',\n",
       "  'd000.s076'],\n",
       " 'd000.s056': ['d000.s002',\n",
       "  'd000.s023',\n",
       "  'd000.s052',\n",
       "  'd000.s053',\n",
       "  'd000.s054',\n",
       "  'd000.s055',\n",
       "  'd000.s056',\n",
       "  'd000.s057',\n",
       "  'd000.s058',\n",
       "  'd000.s059',\n",
       "  'd000.s060'],\n",
       " 'd000.s057': ['d000.s026',\n",
       "  'd000.s053',\n",
       "  'd000.s054',\n",
       "  'd000.s055',\n",
       "  'd000.s056',\n",
       "  'd000.s057',\n",
       "  'd000.s058',\n",
       "  'd000.s059',\n",
       "  'd000.s060',\n",
       "  'd000.s061',\n",
       "  'd000.s115',\n",
       "  'd000.s121'],\n",
       " 'd000.s058': ['d000.s050',\n",
       "  'd000.s054',\n",
       "  'd000.s055',\n",
       "  'd000.s056',\n",
       "  'd000.s057',\n",
       "  'd000.s058',\n",
       "  'd000.s059',\n",
       "  'd000.s060',\n",
       "  'd000.s061',\n",
       "  'd000.s062',\n",
       "  'd000.s115'],\n",
       " 'd000.s059': ['d000.s016',\n",
       "  'd000.s030',\n",
       "  'd000.s036',\n",
       "  'd000.s055',\n",
       "  'd000.s056',\n",
       "  'd000.s057',\n",
       "  'd000.s058',\n",
       "  'd000.s059',\n",
       "  'd000.s060',\n",
       "  'd000.s061',\n",
       "  'd000.s062',\n",
       "  'd000.s063',\n",
       "  'd000.s066'],\n",
       " 'd000.s060': ['d000.s029',\n",
       "  'd000.s050',\n",
       "  'd000.s056',\n",
       "  'd000.s057',\n",
       "  'd000.s058',\n",
       "  'd000.s059',\n",
       "  'd000.s060',\n",
       "  'd000.s061',\n",
       "  'd000.s062',\n",
       "  'd000.s063',\n",
       "  'd000.s064',\n",
       "  'd000.s107'],\n",
       " 'd000.s061': ['d000.s029',\n",
       "  'd000.s050',\n",
       "  'd000.s057',\n",
       "  'd000.s058',\n",
       "  'd000.s059',\n",
       "  'd000.s060',\n",
       "  'd000.s061',\n",
       "  'd000.s062',\n",
       "  'd000.s063',\n",
       "  'd000.s064',\n",
       "  'd000.s065',\n",
       "  'd000.s066'],\n",
       " 'd000.s062': ['d000.s029',\n",
       "  'd000.s057',\n",
       "  'd000.s058',\n",
       "  'd000.s059',\n",
       "  'd000.s060',\n",
       "  'd000.s061',\n",
       "  'd000.s062',\n",
       "  'd000.s063',\n",
       "  'd000.s064',\n",
       "  'd000.s065',\n",
       "  'd000.s066',\n",
       "  'd000.s097',\n",
       "  'd000.s108'],\n",
       " 'd000.s063': ['d000.s010',\n",
       "  'd000.s059',\n",
       "  'd000.s060',\n",
       "  'd000.s061',\n",
       "  'd000.s062',\n",
       "  'd000.s063',\n",
       "  'd000.s064',\n",
       "  'd000.s065',\n",
       "  'd000.s066',\n",
       "  'd000.s067',\n",
       "  'd000.s078',\n",
       "  'd000.s091'],\n",
       " 'd000.s064': ['d000.s000',\n",
       "  'd000.s017',\n",
       "  'd000.s028',\n",
       "  'd000.s060',\n",
       "  'd000.s061',\n",
       "  'd000.s062',\n",
       "  'd000.s063',\n",
       "  'd000.s064',\n",
       "  'd000.s065',\n",
       "  'd000.s066',\n",
       "  'd000.s067',\n",
       "  'd000.s068',\n",
       "  'd000.s086'],\n",
       " 'd000.s065': ['d000.s000',\n",
       "  'd000.s001',\n",
       "  'd000.s005',\n",
       "  'd000.s034',\n",
       "  'd000.s061',\n",
       "  'd000.s062',\n",
       "  'd000.s063',\n",
       "  'd000.s064',\n",
       "  'd000.s065',\n",
       "  'd000.s066',\n",
       "  'd000.s067',\n",
       "  'd000.s068',\n",
       "  'd000.s069'],\n",
       " 'd000.s066': ['d000.s000',\n",
       "  'd000.s009',\n",
       "  'd000.s062',\n",
       "  'd000.s063',\n",
       "  'd000.s064',\n",
       "  'd000.s065',\n",
       "  'd000.s066',\n",
       "  'd000.s067',\n",
       "  'd000.s068',\n",
       "  'd000.s069',\n",
       "  'd000.s070',\n",
       "  'd000.s086'],\n",
       " 'd000.s067': ['d000.s008',\n",
       "  'd000.s026',\n",
       "  'd000.s056',\n",
       "  'd000.s063',\n",
       "  'd000.s064',\n",
       "  'd000.s065',\n",
       "  'd000.s066',\n",
       "  'd000.s067',\n",
       "  'd000.s068',\n",
       "  'd000.s069',\n",
       "  'd000.s070',\n",
       "  'd000.s071',\n",
       "  'd000.s121'],\n",
       " 'd000.s068': ['d000.s023',\n",
       "  'd000.s064',\n",
       "  'd000.s065',\n",
       "  'd000.s066',\n",
       "  'd000.s067',\n",
       "  'd000.s068',\n",
       "  'd000.s069',\n",
       "  'd000.s070',\n",
       "  'd000.s071',\n",
       "  'd000.s072',\n",
       "  'd000.s095'],\n",
       " 'd000.s069': ['d000.s000',\n",
       "  'd000.s001',\n",
       "  'd000.s002',\n",
       "  'd000.s003',\n",
       "  'd000.s065',\n",
       "  'd000.s066',\n",
       "  'd000.s067',\n",
       "  'd000.s068',\n",
       "  'd000.s069',\n",
       "  'd000.s070',\n",
       "  'd000.s071',\n",
       "  'd000.s072',\n",
       "  'd000.s073'],\n",
       " 'd000.s070': ['d000.s023',\n",
       "  'd000.s066',\n",
       "  'd000.s067',\n",
       "  'd000.s068',\n",
       "  'd000.s069',\n",
       "  'd000.s070',\n",
       "  'd000.s071',\n",
       "  'd000.s072',\n",
       "  'd000.s073',\n",
       "  'd000.s074',\n",
       "  'd000.s114'],\n",
       " 'd000.s071': ['d000.s023',\n",
       "  'd000.s067',\n",
       "  'd000.s068',\n",
       "  'd000.s069',\n",
       "  'd000.s070',\n",
       "  'd000.s071',\n",
       "  'd000.s072',\n",
       "  'd000.s073',\n",
       "  'd000.s074',\n",
       "  'd000.s075',\n",
       "  'd000.s114'],\n",
       " 'd000.s072': ['d000.s000',\n",
       "  'd000.s002',\n",
       "  'd000.s034',\n",
       "  'd000.s065',\n",
       "  'd000.s068',\n",
       "  'd000.s069',\n",
       "  'd000.s070',\n",
       "  'd000.s071',\n",
       "  'd000.s072',\n",
       "  'd000.s073',\n",
       "  'd000.s074',\n",
       "  'd000.s075',\n",
       "  'd000.s076'],\n",
       " 'd000.s073': ['d000.s014',\n",
       "  'd000.s066',\n",
       "  'd000.s069',\n",
       "  'd000.s070',\n",
       "  'd000.s071',\n",
       "  'd000.s072',\n",
       "  'd000.s073',\n",
       "  'd000.s074',\n",
       "  'd000.s075',\n",
       "  'd000.s076',\n",
       "  'd000.s077'],\n",
       " 'd000.s074': ['d000.s023',\n",
       "  'd000.s060',\n",
       "  'd000.s070',\n",
       "  'd000.s071',\n",
       "  'd000.s072',\n",
       "  'd000.s073',\n",
       "  'd000.s074',\n",
       "  'd000.s075',\n",
       "  'd000.s076',\n",
       "  'd000.s077',\n",
       "  'd000.s078'],\n",
       " 'd000.s075': ['d000.s009',\n",
       "  'd000.s014',\n",
       "  'd000.s034',\n",
       "  'd000.s065',\n",
       "  'd000.s071',\n",
       "  'd000.s072',\n",
       "  'd000.s073',\n",
       "  'd000.s074',\n",
       "  'd000.s075',\n",
       "  'd000.s076',\n",
       "  'd000.s077',\n",
       "  'd000.s078',\n",
       "  'd000.s079'],\n",
       " 'd000.s076': ['d000.s021',\n",
       "  'd000.s055',\n",
       "  'd000.s072',\n",
       "  'd000.s073',\n",
       "  'd000.s074',\n",
       "  'd000.s075',\n",
       "  'd000.s076',\n",
       "  'd000.s077',\n",
       "  'd000.s078',\n",
       "  'd000.s079',\n",
       "  'd000.s080',\n",
       "  'd000.s081',\n",
       "  'd000.s094'],\n",
       " 'd000.s077': ['d000.s012',\n",
       "  'd000.s013',\n",
       "  'd000.s058',\n",
       "  'd000.s073',\n",
       "  'd000.s074',\n",
       "  'd000.s075',\n",
       "  'd000.s076',\n",
       "  'd000.s077',\n",
       "  'd000.s078',\n",
       "  'd000.s079',\n",
       "  'd000.s080',\n",
       "  'd000.s081'],\n",
       " 'd000.s078': ['d000.s014',\n",
       "  'd000.s034',\n",
       "  'd000.s074',\n",
       "  'd000.s075',\n",
       "  'd000.s076',\n",
       "  'd000.s077',\n",
       "  'd000.s078',\n",
       "  'd000.s079',\n",
       "  'd000.s080',\n",
       "  'd000.s081',\n",
       "  'd000.s082',\n",
       "  'd000.s085',\n",
       "  'd000.s101'],\n",
       " 'd000.s079': ['d000.s009',\n",
       "  'd000.s014',\n",
       "  'd000.s015',\n",
       "  'd000.s075',\n",
       "  'd000.s076',\n",
       "  'd000.s077',\n",
       "  'd000.s078',\n",
       "  'd000.s079',\n",
       "  'd000.s080',\n",
       "  'd000.s081',\n",
       "  'd000.s082',\n",
       "  'd000.s083'],\n",
       " 'd000.s080': ['d000.s004',\n",
       "  'd000.s054',\n",
       "  'd000.s076',\n",
       "  'd000.s077',\n",
       "  'd000.s078',\n",
       "  'd000.s079',\n",
       "  'd000.s080',\n",
       "  'd000.s081',\n",
       "  'd000.s082',\n",
       "  'd000.s083',\n",
       "  'd000.s084',\n",
       "  'd000.s111',\n",
       "  'd000.s113'],\n",
       " 'd000.s081': ['d000.s016',\n",
       "  'd000.s033',\n",
       "  'd000.s048',\n",
       "  'd000.s077',\n",
       "  'd000.s078',\n",
       "  'd000.s079',\n",
       "  'd000.s080',\n",
       "  'd000.s081',\n",
       "  'd000.s082',\n",
       "  'd000.s083',\n",
       "  'd000.s084',\n",
       "  'd000.s085',\n",
       "  'd000.s112'],\n",
       " 'd000.s082': ['d000.s001',\n",
       "  'd000.s012',\n",
       "  'd000.s013',\n",
       "  'd000.s078',\n",
       "  'd000.s079',\n",
       "  'd000.s080',\n",
       "  'd000.s081',\n",
       "  'd000.s082',\n",
       "  'd000.s083',\n",
       "  'd000.s084',\n",
       "  'd000.s085',\n",
       "  'd000.s086',\n",
       "  'd000.s134'],\n",
       " 'd000.s083': ['d000.s065',\n",
       "  'd000.s079',\n",
       "  'd000.s080',\n",
       "  'd000.s081',\n",
       "  'd000.s082',\n",
       "  'd000.s083',\n",
       "  'd000.s084',\n",
       "  'd000.s085',\n",
       "  'd000.s086',\n",
       "  'd000.s087',\n",
       "  'd000.s101',\n",
       "  'd000.s119',\n",
       "  'd000.s129'],\n",
       " 'd000.s084': ['d000.s013',\n",
       "  'd000.s014',\n",
       "  'd000.s016',\n",
       "  'd000.s079',\n",
       "  'd000.s080',\n",
       "  'd000.s081',\n",
       "  'd000.s082',\n",
       "  'd000.s083',\n",
       "  'd000.s084',\n",
       "  'd000.s085',\n",
       "  'd000.s086',\n",
       "  'd000.s087',\n",
       "  'd000.s088'],\n",
       " 'd000.s085': ['d000.s017',\n",
       "  'd000.s043',\n",
       "  'd000.s078',\n",
       "  'd000.s081',\n",
       "  'd000.s082',\n",
       "  'd000.s083',\n",
       "  'd000.s084',\n",
       "  'd000.s085',\n",
       "  'd000.s086',\n",
       "  'd000.s087',\n",
       "  'd000.s088',\n",
       "  'd000.s089'],\n",
       " 'd000.s086': ['d000.s017',\n",
       "  'd000.s018',\n",
       "  'd000.s064',\n",
       "  'd000.s082',\n",
       "  'd000.s083',\n",
       "  'd000.s084',\n",
       "  'd000.s085',\n",
       "  'd000.s086',\n",
       "  'd000.s087',\n",
       "  'd000.s088',\n",
       "  'd000.s089',\n",
       "  'd000.s090'],\n",
       " 'd000.s087': ['d000.s023',\n",
       "  'd000.s028',\n",
       "  'd000.s031',\n",
       "  'd000.s083',\n",
       "  'd000.s084',\n",
       "  'd000.s085',\n",
       "  'd000.s086',\n",
       "  'd000.s087',\n",
       "  'd000.s088',\n",
       "  'd000.s089',\n",
       "  'd000.s090',\n",
       "  'd000.s091'],\n",
       " 'd000.s088': ['d000.s013',\n",
       "  'd000.s084',\n",
       "  'd000.s085',\n",
       "  'd000.s086',\n",
       "  'd000.s087',\n",
       "  'd000.s088',\n",
       "  'd000.s089',\n",
       "  'd000.s090',\n",
       "  'd000.s091',\n",
       "  'd000.s092',\n",
       "  'd000.s093',\n",
       "  'd000.s094',\n",
       "  'd000.s114'],\n",
       " 'd000.s089': ['d000.s014',\n",
       "  'd000.s031',\n",
       "  'd000.s085',\n",
       "  'd000.s086',\n",
       "  'd000.s087',\n",
       "  'd000.s088',\n",
       "  'd000.s089',\n",
       "  'd000.s090',\n",
       "  'd000.s091',\n",
       "  'd000.s092',\n",
       "  'd000.s093',\n",
       "  'd000.s094',\n",
       "  'd000.s124'],\n",
       " 'd000.s090': ['d000.s014',\n",
       "  'd000.s086',\n",
       "  'd000.s087',\n",
       "  'd000.s088',\n",
       "  'd000.s089',\n",
       "  'd000.s090',\n",
       "  'd000.s091',\n",
       "  'd000.s092',\n",
       "  'd000.s093',\n",
       "  'd000.s094'],\n",
       " 'd000.s091': ['d000.s059',\n",
       "  'd000.s063',\n",
       "  'd000.s087',\n",
       "  'd000.s088',\n",
       "  'd000.s089',\n",
       "  'd000.s090',\n",
       "  'd000.s091',\n",
       "  'd000.s092',\n",
       "  'd000.s093',\n",
       "  'd000.s094',\n",
       "  'd000.s095',\n",
       "  'd000.s098',\n",
       "  'd000.s134'],\n",
       " 'd000.s092': ['d000.s017',\n",
       "  'd000.s023',\n",
       "  'd000.s028',\n",
       "  'd000.s060',\n",
       "  'd000.s088',\n",
       "  'd000.s089',\n",
       "  'd000.s090',\n",
       "  'd000.s091',\n",
       "  'd000.s092',\n",
       "  'd000.s093',\n",
       "  'd000.s094',\n",
       "  'd000.s095',\n",
       "  'd000.s096'],\n",
       " 'd000.s093': ['d000.s012',\n",
       "  'd000.s021',\n",
       "  'd000.s031',\n",
       "  'd000.s088',\n",
       "  'd000.s089',\n",
       "  'd000.s090',\n",
       "  'd000.s091',\n",
       "  'd000.s092',\n",
       "  'd000.s093',\n",
       "  'd000.s094',\n",
       "  'd000.s095',\n",
       "  'd000.s096',\n",
       "  'd000.s097'],\n",
       " 'd000.s094': ['d000.s013',\n",
       "  'd000.s014',\n",
       "  'd000.s040',\n",
       "  'd000.s076',\n",
       "  'd000.s090',\n",
       "  'd000.s091',\n",
       "  'd000.s092',\n",
       "  'd000.s093',\n",
       "  'd000.s094',\n",
       "  'd000.s095',\n",
       "  'd000.s096',\n",
       "  'd000.s097',\n",
       "  'd000.s098'],\n",
       " 'd000.s095': ['d000.s014',\n",
       "  'd000.s034',\n",
       "  'd000.s068',\n",
       "  'd000.s075',\n",
       "  'd000.s091',\n",
       "  'd000.s092',\n",
       "  'd000.s093',\n",
       "  'd000.s094',\n",
       "  'd000.s095',\n",
       "  'd000.s096',\n",
       "  'd000.s097',\n",
       "  'd000.s098',\n",
       "  'd000.s099'],\n",
       " 'd000.s096': ['d000.s056',\n",
       "  'd000.s068',\n",
       "  'd000.s092',\n",
       "  'd000.s093',\n",
       "  'd000.s094',\n",
       "  'd000.s095',\n",
       "  'd000.s096',\n",
       "  'd000.s097',\n",
       "  'd000.s098',\n",
       "  'd000.s099',\n",
       "  'd000.s100',\n",
       "  'd000.s112',\n",
       "  'd000.s118'],\n",
       " 'd000.s097': ['d000.s078',\n",
       "  'd000.s085',\n",
       "  'd000.s093',\n",
       "  'd000.s094',\n",
       "  'd000.s095',\n",
       "  'd000.s096',\n",
       "  'd000.s097',\n",
       "  'd000.s098',\n",
       "  'd000.s099',\n",
       "  'd000.s100',\n",
       "  'd000.s101',\n",
       "  'd000.s114'],\n",
       " 'd000.s098': ['d000.s007',\n",
       "  'd000.s089',\n",
       "  'd000.s094',\n",
       "  'd000.s095',\n",
       "  'd000.s096',\n",
       "  'd000.s097',\n",
       "  'd000.s098',\n",
       "  'd000.s099',\n",
       "  'd000.s100',\n",
       "  'd000.s101',\n",
       "  'd000.s102',\n",
       "  'd000.s124'],\n",
       " 'd000.s099': ['d000.s068',\n",
       "  'd000.s071',\n",
       "  'd000.s095',\n",
       "  'd000.s096',\n",
       "  'd000.s097',\n",
       "  'd000.s098',\n",
       "  'd000.s099',\n",
       "  'd000.s100',\n",
       "  'd000.s101',\n",
       "  'd000.s102',\n",
       "  'd000.s103',\n",
       "  'd000.s115'],\n",
       " 'd000.s100': ['d000.s000',\n",
       "  'd000.s027',\n",
       "  'd000.s029',\n",
       "  'd000.s096',\n",
       "  'd000.s097',\n",
       "  'd000.s098',\n",
       "  'd000.s099',\n",
       "  'd000.s100',\n",
       "  'd000.s101',\n",
       "  'd000.s102',\n",
       "  'd000.s103',\n",
       "  'd000.s104',\n",
       "  'd000.s124'],\n",
       " 'd000.s101': ['d000.s078',\n",
       "  'd000.s083',\n",
       "  'd000.s097',\n",
       "  'd000.s098',\n",
       "  'd000.s099',\n",
       "  'd000.s100',\n",
       "  'd000.s101',\n",
       "  'd000.s102',\n",
       "  'd000.s103',\n",
       "  'd000.s104',\n",
       "  'd000.s105',\n",
       "  'd000.s119'],\n",
       " 'd000.s102': ['d000.s021',\n",
       "  'd000.s034',\n",
       "  'd000.s098',\n",
       "  'd000.s099',\n",
       "  'd000.s100',\n",
       "  'd000.s101',\n",
       "  'd000.s102',\n",
       "  'd000.s103',\n",
       "  'd000.s104',\n",
       "  'd000.s105',\n",
       "  'd000.s106',\n",
       "  'd000.s124',\n",
       "  'd000.s130'],\n",
       " 'd000.s103': ['d000.s099',\n",
       "  'd000.s100',\n",
       "  'd000.s101',\n",
       "  'd000.s102',\n",
       "  'd000.s103',\n",
       "  'd000.s104',\n",
       "  'd000.s105',\n",
       "  'd000.s106',\n",
       "  'd000.s107',\n",
       "  'd000.s115',\n",
       "  'd000.s129'],\n",
       " 'd000.s104': ['d000.s000',\n",
       "  'd000.s001',\n",
       "  'd000.s002',\n",
       "  'd000.s100',\n",
       "  'd000.s101',\n",
       "  'd000.s102',\n",
       "  'd000.s103',\n",
       "  'd000.s104',\n",
       "  'd000.s105',\n",
       "  'd000.s106',\n",
       "  'd000.s107',\n",
       "  'd000.s108'],\n",
       " 'd000.s105': ['d000.s055',\n",
       "  'd000.s101',\n",
       "  'd000.s102',\n",
       "  'd000.s103',\n",
       "  'd000.s104',\n",
       "  'd000.s105',\n",
       "  'd000.s106',\n",
       "  'd000.s107',\n",
       "  'd000.s108',\n",
       "  'd000.s109',\n",
       "  'd000.s114'],\n",
       " 'd000.s106': ['d000.s055',\n",
       "  'd000.s102',\n",
       "  'd000.s103',\n",
       "  'd000.s104',\n",
       "  'd000.s105',\n",
       "  'd000.s106',\n",
       "  'd000.s107',\n",
       "  'd000.s108',\n",
       "  'd000.s109',\n",
       "  'd000.s110',\n",
       "  'd000.s131'],\n",
       " 'd000.s107': ['d000.s012',\n",
       "  'd000.s103',\n",
       "  'd000.s104',\n",
       "  'd000.s105',\n",
       "  'd000.s106',\n",
       "  'd000.s107',\n",
       "  'd000.s108',\n",
       "  'd000.s109',\n",
       "  'd000.s110',\n",
       "  'd000.s111',\n",
       "  'd000.s115',\n",
       "  'd000.s129',\n",
       "  'd000.s134'],\n",
       " 'd000.s108': ['d000.s023',\n",
       "  'd000.s029',\n",
       "  'd000.s072',\n",
       "  'd000.s104',\n",
       "  'd000.s105',\n",
       "  'd000.s106',\n",
       "  'd000.s107',\n",
       "  'd000.s108',\n",
       "  'd000.s109',\n",
       "  'd000.s110',\n",
       "  'd000.s111',\n",
       "  'd000.s112'],\n",
       " 'd000.s109': ['d000.s021',\n",
       "  'd000.s105',\n",
       "  'd000.s106',\n",
       "  'd000.s107',\n",
       "  'd000.s108',\n",
       "  'd000.s109',\n",
       "  'd000.s110',\n",
       "  'd000.s111',\n",
       "  'd000.s112',\n",
       "  'd000.s113'],\n",
       " 'd000.s110': ['d000.s023',\n",
       "  'd000.s068',\n",
       "  'd000.s070',\n",
       "  'd000.s071',\n",
       "  'd000.s106',\n",
       "  'd000.s107',\n",
       "  'd000.s108',\n",
       "  'd000.s109',\n",
       "  'd000.s110',\n",
       "  'd000.s111',\n",
       "  'd000.s112',\n",
       "  'd000.s113',\n",
       "  'd000.s114'],\n",
       " 'd000.s111': ['d000.s036',\n",
       "  'd000.s107',\n",
       "  'd000.s108',\n",
       "  'd000.s109',\n",
       "  'd000.s110',\n",
       "  'd000.s111',\n",
       "  'd000.s112',\n",
       "  'd000.s113',\n",
       "  'd000.s114',\n",
       "  'd000.s115',\n",
       "  'd000.s119'],\n",
       " 'd000.s112': ['d000.s036',\n",
       "  'd000.s048',\n",
       "  'd000.s055',\n",
       "  'd000.s081',\n",
       "  'd000.s108',\n",
       "  'd000.s109',\n",
       "  'd000.s110',\n",
       "  'd000.s111',\n",
       "  'd000.s112',\n",
       "  'd000.s113',\n",
       "  'd000.s114',\n",
       "  'd000.s115',\n",
       "  'd000.s116'],\n",
       " 'd000.s113': ['d000.s021',\n",
       "  'd000.s109',\n",
       "  'd000.s110',\n",
       "  'd000.s111',\n",
       "  'd000.s112',\n",
       "  'd000.s113',\n",
       "  'd000.s114',\n",
       "  'd000.s115',\n",
       "  'd000.s116',\n",
       "  'd000.s117',\n",
       "  'd000.s119'],\n",
       " 'd000.s114': ['d000.s068',\n",
       "  'd000.s071',\n",
       "  'd000.s085',\n",
       "  'd000.s097',\n",
       "  'd000.s110',\n",
       "  'd000.s111',\n",
       "  'd000.s112',\n",
       "  'd000.s113',\n",
       "  'd000.s114',\n",
       "  'd000.s115',\n",
       "  'd000.s116',\n",
       "  'd000.s117',\n",
       "  'd000.s118'],\n",
       " 'd000.s115': ['d000.s057',\n",
       "  'd000.s111',\n",
       "  'd000.s112',\n",
       "  'd000.s113',\n",
       "  'd000.s114',\n",
       "  'd000.s115',\n",
       "  'd000.s116',\n",
       "  'd000.s117',\n",
       "  'd000.s118',\n",
       "  'd000.s119',\n",
       "  'd000.s122',\n",
       "  'd000.s129',\n",
       "  'd000.s134'],\n",
       " 'd000.s116': ['d000.s000',\n",
       "  'd000.s001',\n",
       "  'd000.s002',\n",
       "  'd000.s003',\n",
       "  'd000.s112',\n",
       "  'd000.s113',\n",
       "  'd000.s114',\n",
       "  'd000.s115',\n",
       "  'd000.s116',\n",
       "  'd000.s117',\n",
       "  'd000.s118',\n",
       "  'd000.s119',\n",
       "  'd000.s120'],\n",
       " 'd000.s117': ['d000.s000',\n",
       "  'd000.s001',\n",
       "  'd000.s002',\n",
       "  'd000.s003',\n",
       "  'd000.s113',\n",
       "  'd000.s114',\n",
       "  'd000.s115',\n",
       "  'd000.s116',\n",
       "  'd000.s117',\n",
       "  'd000.s118',\n",
       "  'd000.s119',\n",
       "  'd000.s120',\n",
       "  'd000.s121'],\n",
       " 'd000.s118': ['d000.s020',\n",
       "  'd000.s032',\n",
       "  'd000.s037',\n",
       "  'd000.s096',\n",
       "  'd000.s114',\n",
       "  'd000.s115',\n",
       "  'd000.s116',\n",
       "  'd000.s117',\n",
       "  'd000.s118',\n",
       "  'd000.s119',\n",
       "  'd000.s120',\n",
       "  'd000.s121',\n",
       "  'd000.s122'],\n",
       " 'd000.s119': ['d000.s020',\n",
       "  'd000.s111',\n",
       "  'd000.s113',\n",
       "  'd000.s115',\n",
       "  'd000.s116',\n",
       "  'd000.s117',\n",
       "  'd000.s118',\n",
       "  'd000.s119',\n",
       "  'd000.s120',\n",
       "  'd000.s121',\n",
       "  'd000.s122',\n",
       "  'd000.s123'],\n",
       " 'd000.s120': ['d000.s000',\n",
       "  'd000.s008',\n",
       "  'd000.s022',\n",
       "  'd000.s085',\n",
       "  'd000.s116',\n",
       "  'd000.s117',\n",
       "  'd000.s118',\n",
       "  'd000.s119',\n",
       "  'd000.s120',\n",
       "  'd000.s121',\n",
       "  'd000.s122',\n",
       "  'd000.s123',\n",
       "  'd000.s124'],\n",
       " 'd000.s121': ['d000.s026',\n",
       "  'd000.s041',\n",
       "  'd000.s053',\n",
       "  'd000.s057',\n",
       "  'd000.s117',\n",
       "  'd000.s118',\n",
       "  'd000.s119',\n",
       "  'd000.s120',\n",
       "  'd000.s121',\n",
       "  'd000.s122',\n",
       "  'd000.s123',\n",
       "  'd000.s124',\n",
       "  'd000.s125'],\n",
       " 'd000.s122': ['d000.s020',\n",
       "  'd000.s027',\n",
       "  'd000.s115',\n",
       "  'd000.s118',\n",
       "  'd000.s119',\n",
       "  'd000.s120',\n",
       "  'd000.s121',\n",
       "  'd000.s122',\n",
       "  'd000.s123',\n",
       "  'd000.s124',\n",
       "  'd000.s125',\n",
       "  'd000.s126',\n",
       "  'd000.s134'],\n",
       " 'd000.s123': ['d000.s000',\n",
       "  'd000.s001',\n",
       "  'd000.s002',\n",
       "  'd000.s119',\n",
       "  'd000.s120',\n",
       "  'd000.s121',\n",
       "  'd000.s122',\n",
       "  'd000.s123',\n",
       "  'd000.s124',\n",
       "  'd000.s125',\n",
       "  'd000.s126',\n",
       "  'd000.s127',\n",
       "  'd000.s132'],\n",
       " 'd000.s124': ['d000.s026',\n",
       "  'd000.s027',\n",
       "  'd000.s089',\n",
       "  'd000.s100',\n",
       "  'd000.s120',\n",
       "  'd000.s121',\n",
       "  'd000.s122',\n",
       "  'd000.s123',\n",
       "  'd000.s124',\n",
       "  'd000.s125',\n",
       "  'd000.s126',\n",
       "  'd000.s127',\n",
       "  'd000.s128'],\n",
       " 'd000.s125': ['d000.s060',\n",
       "  'd000.s102',\n",
       "  'd000.s121',\n",
       "  'd000.s122',\n",
       "  'd000.s123',\n",
       "  'd000.s124',\n",
       "  'd000.s125',\n",
       "  'd000.s126',\n",
       "  'd000.s127',\n",
       "  'd000.s128',\n",
       "  'd000.s129',\n",
       "  'd000.s134'],\n",
       " 'd000.s126': ['d000.s122',\n",
       "  'd000.s123',\n",
       "  'd000.s124',\n",
       "  'd000.s125',\n",
       "  'd000.s126',\n",
       "  'd000.s127',\n",
       "  'd000.s128',\n",
       "  'd000.s129',\n",
       "  'd000.s130'],\n",
       " 'd000.s127': ['d000.s014',\n",
       "  'd000.s036',\n",
       "  'd000.s075',\n",
       "  'd000.s123',\n",
       "  'd000.s124',\n",
       "  'd000.s125',\n",
       "  'd000.s126',\n",
       "  'd000.s127',\n",
       "  'd000.s128',\n",
       "  'd000.s129',\n",
       "  'd000.s130',\n",
       "  'd000.s131'],\n",
       " 'd000.s128': ['d000.s000',\n",
       "  'd000.s001',\n",
       "  'd000.s039',\n",
       "  'd000.s053',\n",
       "  'd000.s124',\n",
       "  'd000.s125',\n",
       "  'd000.s126',\n",
       "  'd000.s127',\n",
       "  'd000.s128',\n",
       "  'd000.s129',\n",
       "  'd000.s130',\n",
       "  'd000.s131',\n",
       "  'd000.s132'],\n",
       " 'd000.s129': ['d000.s012',\n",
       "  'd000.s028',\n",
       "  'd000.s115',\n",
       "  'd000.s125',\n",
       "  'd000.s126',\n",
       "  'd000.s127',\n",
       "  'd000.s128',\n",
       "  'd000.s129',\n",
       "  'd000.s130',\n",
       "  'd000.s131',\n",
       "  'd000.s132',\n",
       "  'd000.s133',\n",
       "  'd000.s134'],\n",
       " 'd000.s130': ['d000.s028',\n",
       "  'd000.s100',\n",
       "  'd000.s102',\n",
       "  'd000.s126',\n",
       "  'd000.s127',\n",
       "  'd000.s128',\n",
       "  'd000.s129',\n",
       "  'd000.s130',\n",
       "  'd000.s131',\n",
       "  'd000.s132',\n",
       "  'd000.s133',\n",
       "  'd000.s134'],\n",
       " 'd000.s131': ['d000.s023',\n",
       "  'd000.s051',\n",
       "  'd000.s053',\n",
       "  'd000.s054',\n",
       "  'd000.s127',\n",
       "  'd000.s128',\n",
       "  'd000.s129',\n",
       "  'd000.s130',\n",
       "  'd000.s131',\n",
       "  'd000.s132',\n",
       "  'd000.s133',\n",
       "  'd000.s134',\n",
       "  'd000.s135'],\n",
       " 'd000.s132': ['d000.s034',\n",
       "  'd000.s051',\n",
       "  'd000.s123',\n",
       "  'd000.s128',\n",
       "  'd000.s129',\n",
       "  'd000.s130',\n",
       "  'd000.s131',\n",
       "  'd000.s132',\n",
       "  'd000.s133',\n",
       "  'd000.s134',\n",
       "  'd000.s135'],\n",
       " 'd000.s133': ['d000.s051',\n",
       "  'd000.s053',\n",
       "  'd000.s054',\n",
       "  'd000.s129',\n",
       "  'd000.s130',\n",
       "  'd000.s131',\n",
       "  'd000.s132',\n",
       "  'd000.s133',\n",
       "  'd000.s134',\n",
       "  'd000.s135'],\n",
       " 'd000.s134': ['d000.s107',\n",
       "  'd000.s115',\n",
       "  'd000.s129',\n",
       "  'd000.s130',\n",
       "  'd000.s131',\n",
       "  'd000.s132',\n",
       "  'd000.s133',\n",
       "  'd000.s134',\n",
       "  'd000.s135'],\n",
       " 'd000.s135': ['d000.s051',\n",
       "  'd000.s057',\n",
       "  'd000.s115',\n",
       "  'd000.s131',\n",
       "  'd000.s132',\n",
       "  'd000.s133',\n",
       "  'd000.s134',\n",
       "  'd000.s135'],\n",
       " 'd001.s000': ['d001.s000',\n",
       "  'd001.s001',\n",
       "  'd001.s002',\n",
       "  'd001.s003',\n",
       "  'd001.s004',\n",
       "  'd001.s049',\n",
       "  'd001.s090',\n",
       "  'd001.s114'],\n",
       " 'd001.s001': ['d001.s000',\n",
       "  'd001.s001',\n",
       "  'd001.s002',\n",
       "  'd001.s003',\n",
       "  'd001.s004',\n",
       "  'd001.s005',\n",
       "  'd001.s012',\n",
       "  'd001.s018',\n",
       "  'd001.s033',\n",
       "  'd001.s109'],\n",
       " 'd001.s002': ['d001.s000',\n",
       "  'd001.s001',\n",
       "  'd001.s002',\n",
       "  'd001.s003',\n",
       "  'd001.s004',\n",
       "  'd001.s005',\n",
       "  'd001.s006'],\n",
       " 'd001.s003': ['d001.s000',\n",
       "  'd001.s001',\n",
       "  'd001.s002',\n",
       "  'd001.s003',\n",
       "  'd001.s004',\n",
       "  'd001.s005',\n",
       "  'd001.s006',\n",
       "  'd001.s007',\n",
       "  'd001.s020',\n",
       "  'd001.s045',\n",
       "  'd001.s049',\n",
       "  'd001.s090'],\n",
       " 'd001.s004': ['d001.s000',\n",
       "  'd001.s001',\n",
       "  'd001.s002',\n",
       "  'd001.s003',\n",
       "  'd001.s004',\n",
       "  'd001.s005',\n",
       "  'd001.s006',\n",
       "  'd001.s007',\n",
       "  'd001.s008',\n",
       "  'd001.s033',\n",
       "  'd001.s034',\n",
       "  'd001.s040',\n",
       "  'd001.s049'],\n",
       " 'd001.s005': ['d001.s001',\n",
       "  'd001.s002',\n",
       "  'd001.s003',\n",
       "  'd001.s004',\n",
       "  'd001.s005',\n",
       "  'd001.s006',\n",
       "  'd001.s007',\n",
       "  'd001.s008',\n",
       "  'd001.s010',\n",
       "  'd001.s063',\n",
       "  'd001.s065',\n",
       "  'd001.s084',\n",
       "  'd001.s119'],\n",
       " 'd001.s006': ['d001.s000',\n",
       "  'd001.s002',\n",
       "  'd001.s003',\n",
       "  'd001.s004',\n",
       "  'd001.s005',\n",
       "  'd001.s006',\n",
       "  'd001.s007',\n",
       "  'd001.s008',\n",
       "  'd001.s010',\n",
       "  'd001.s011',\n",
       "  'd001.s086',\n",
       "  'd001.s117'],\n",
       " 'd001.s007': ['d001.s003',\n",
       "  'd001.s004',\n",
       "  'd001.s005',\n",
       "  'd001.s006',\n",
       "  'd001.s007',\n",
       "  'd001.s008',\n",
       "  'd001.s010',\n",
       "  'd001.s011',\n",
       "  'd001.s012',\n",
       "  'd001.s029',\n",
       "  'd001.s040',\n",
       "  'd001.s049',\n",
       "  'd001.s134'],\n",
       " 'd001.s008': ['d001.s004',\n",
       "  'd001.s005',\n",
       "  'd001.s006',\n",
       "  'd001.s007',\n",
       "  'd001.s008',\n",
       "  'd001.s010',\n",
       "  'd001.s011',\n",
       "  'd001.s012',\n",
       "  'd001.s013',\n",
       "  'd001.s033',\n",
       "  'd001.s049',\n",
       "  'd001.s050'],\n",
       " 'd001.s010': ['d001.s005',\n",
       "  'd001.s006',\n",
       "  'd001.s007',\n",
       "  'd001.s008',\n",
       "  'd001.s010',\n",
       "  'd001.s011',\n",
       "  'd001.s012',\n",
       "  'd001.s013',\n",
       "  'd001.s014',\n",
       "  'd001.s033',\n",
       "  'd001.s040',\n",
       "  'd001.s049',\n",
       "  'd001.s135'],\n",
       " 'd001.s011': ['d001.s000',\n",
       "  'd001.s001',\n",
       "  'd001.s002',\n",
       "  'd001.s003',\n",
       "  'd001.s006',\n",
       "  'd001.s007',\n",
       "  'd001.s008',\n",
       "  'd001.s010',\n",
       "  'd001.s011',\n",
       "  'd001.s012',\n",
       "  'd001.s013',\n",
       "  'd001.s014',\n",
       "  'd001.s015'],\n",
       " 'd001.s012': ['d001.s001',\n",
       "  'd001.s007',\n",
       "  'd001.s008',\n",
       "  'd001.s010',\n",
       "  'd001.s011',\n",
       "  'd001.s012',\n",
       "  'd001.s013',\n",
       "  'd001.s014',\n",
       "  'd001.s015',\n",
       "  'd001.s016',\n",
       "  'd001.s018',\n",
       "  'd001.s033',\n",
       "  'd001.s109'],\n",
       " 'd001.s013': ['d001.s000',\n",
       "  'd001.s001',\n",
       "  'd001.s007',\n",
       "  'd001.s008',\n",
       "  'd001.s010',\n",
       "  'd001.s011',\n",
       "  'd001.s012',\n",
       "  'd001.s013',\n",
       "  'd001.s014',\n",
       "  'd001.s015',\n",
       "  'd001.s016',\n",
       "  'd001.s017',\n",
       "  'd001.s019'],\n",
       " 'd001.s014': ['d001.s010',\n",
       "  'd001.s011',\n",
       "  'd001.s012',\n",
       "  'd001.s013',\n",
       "  'd001.s014',\n",
       "  'd001.s015',\n",
       "  'd001.s016',\n",
       "  'd001.s017',\n",
       "  'd001.s018',\n",
       "  'd001.s020',\n",
       "  'd001.s033',\n",
       "  'd001.s048',\n",
       "  'd001.s073'],\n",
       " 'd001.s015': ['d001.s011',\n",
       "  'd001.s012',\n",
       "  'd001.s013',\n",
       "  'd001.s014',\n",
       "  'd001.s015',\n",
       "  'd001.s016',\n",
       "  'd001.s017',\n",
       "  'd001.s018',\n",
       "  'd001.s019',\n",
       "  'd001.s033',\n",
       "  'd001.s038',\n",
       "  'd001.s048'],\n",
       " 'd001.s016': ['d001.s012',\n",
       "  'd001.s013',\n",
       "  'd001.s014',\n",
       "  'd001.s015',\n",
       "  'd001.s016',\n",
       "  'd001.s017',\n",
       "  'd001.s018',\n",
       "  'd001.s019',\n",
       "  'd001.s020',\n",
       "  'd001.s033',\n",
       "  'd001.s063',\n",
       "  'd001.s075',\n",
       "  'd001.s078'],\n",
       " 'd001.s017': ['d001.s000',\n",
       "  'd001.s001',\n",
       "  'd001.s002',\n",
       "  'd001.s003',\n",
       "  'd001.s013',\n",
       "  'd001.s014',\n",
       "  'd001.s015',\n",
       "  'd001.s016',\n",
       "  'd001.s017',\n",
       "  'd001.s018',\n",
       "  'd001.s019',\n",
       "  'd001.s020',\n",
       "  'd001.s021'],\n",
       " 'd001.s018': ['d001.s014',\n",
       "  'd001.s015',\n",
       "  'd001.s016',\n",
       "  'd001.s017',\n",
       "  'd001.s018',\n",
       "  'd001.s019',\n",
       "  'd001.s020',\n",
       "  'd001.s021',\n",
       "  'd001.s022',\n",
       "  'd001.s033',\n",
       "  'd001.s038',\n",
       "  'd001.s048'],\n",
       " 'd001.s019': ['d001.s015',\n",
       "  'd001.s016',\n",
       "  'd001.s017',\n",
       "  'd001.s018',\n",
       "  'd001.s019',\n",
       "  'd001.s020',\n",
       "  'd001.s021',\n",
       "  'd001.s022',\n",
       "  'd001.s023',\n",
       "  'd001.s030',\n",
       "  'd001.s033',\n",
       "  'd001.s048'],\n",
       " 'd001.s020': ['d001.s003',\n",
       "  'd001.s016',\n",
       "  'd001.s017',\n",
       "  'd001.s018',\n",
       "  'd001.s019',\n",
       "  'd001.s020',\n",
       "  'd001.s021',\n",
       "  'd001.s022',\n",
       "  'd001.s023',\n",
       "  'd001.s024',\n",
       "  'd001.s045',\n",
       "  'd001.s090',\n",
       "  'd001.s119'],\n",
       " 'd001.s021': ['d001.s000',\n",
       "  'd001.s017',\n",
       "  'd001.s018',\n",
       "  'd001.s019',\n",
       "  'd001.s020',\n",
       "  'd001.s021',\n",
       "  'd001.s022',\n",
       "  'd001.s023',\n",
       "  'd001.s024',\n",
       "  'd001.s025',\n",
       "  'd001.s026'],\n",
       " 'd001.s022': ['d001.s018',\n",
       "  'd001.s019',\n",
       "  'd001.s020',\n",
       "  'd001.s021',\n",
       "  'd001.s022',\n",
       "  'd001.s023',\n",
       "  'd001.s024',\n",
       "  'd001.s025',\n",
       "  'd001.s026',\n",
       "  'd001.s093',\n",
       "  'd001.s102',\n",
       "  'd001.s106'],\n",
       " 'd001.s023': ['d001.s019',\n",
       "  'd001.s020',\n",
       "  'd001.s021',\n",
       "  'd001.s022',\n",
       "  'd001.s023',\n",
       "  'd001.s024',\n",
       "  'd001.s025',\n",
       "  'd001.s026',\n",
       "  'd001.s027',\n",
       "  'd001.s029',\n",
       "  'd001.s037',\n",
       "  'd001.s065',\n",
       "  'd001.s134'],\n",
       " 'd001.s024': ['d001.s000',\n",
       "  'd001.s001',\n",
       "  'd001.s002',\n",
       "  'd001.s020',\n",
       "  'd001.s021',\n",
       "  'd001.s022',\n",
       "  'd001.s023',\n",
       "  'd001.s024',\n",
       "  'd001.s025',\n",
       "  'd001.s026',\n",
       "  'd001.s027',\n",
       "  'd001.s029',\n",
       "  'd001.s038'],\n",
       " 'd001.s025': ['d001.s000',\n",
       "  'd001.s001',\n",
       "  'd001.s021',\n",
       "  'd001.s022',\n",
       "  'd001.s023',\n",
       "  'd001.s024',\n",
       "  'd001.s025',\n",
       "  'd001.s026',\n",
       "  'd001.s027',\n",
       "  'd001.s029',\n",
       "  'd001.s030'],\n",
       " 'd001.s026': ['d001.s000',\n",
       "  'd001.s021',\n",
       "  'd001.s022',\n",
       "  'd001.s023',\n",
       "  'd001.s024',\n",
       "  'd001.s025',\n",
       "  'd001.s026',\n",
       "  'd001.s027',\n",
       "  'd001.s029',\n",
       "  'd001.s030',\n",
       "  'd001.s031'],\n",
       " 'd001.s027': ['d001.s000',\n",
       "  'd001.s001',\n",
       "  'd001.s023',\n",
       "  'd001.s024',\n",
       "  'd001.s025',\n",
       "  'd001.s026',\n",
       "  'd001.s027',\n",
       "  'd001.s029',\n",
       "  'd001.s030',\n",
       "  'd001.s031',\n",
       "  'd001.s032',\n",
       "  'd001.s080'],\n",
       " 'd001.s029': ['d001.s023',\n",
       "  'd001.s024',\n",
       "  'd001.s025',\n",
       "  'd001.s026',\n",
       "  'd001.s027',\n",
       "  'd001.s029',\n",
       "  'd001.s030',\n",
       "  'd001.s031',\n",
       "  'd001.s032',\n",
       "  'd001.s033',\n",
       "  'd001.s065',\n",
       "  'd001.s112',\n",
       "  'd001.s134'],\n",
       " 'd001.s030': ['d001.s018',\n",
       "  'd001.s019',\n",
       "  'd001.s025',\n",
       "  'd001.s026',\n",
       "  'd001.s027',\n",
       "  'd001.s029',\n",
       "  'd001.s030',\n",
       "  'd001.s031',\n",
       "  'd001.s032',\n",
       "  'd001.s033',\n",
       "  'd001.s034',\n",
       "  'd001.s048'],\n",
       " 'd001.s031': ['d001.s000',\n",
       "  'd001.s026',\n",
       "  'd001.s027',\n",
       "  'd001.s029',\n",
       "  'd001.s030',\n",
       "  'd001.s031',\n",
       "  'd001.s032',\n",
       "  'd001.s033',\n",
       "  'd001.s034',\n",
       "  'd001.s035',\n",
       "  'd001.s107',\n",
       "  'd001.s136'],\n",
       " 'd001.s032': ['d001.s027',\n",
       "  'd001.s029',\n",
       "  'd001.s030',\n",
       "  'd001.s031',\n",
       "  'd001.s032',\n",
       "  'd001.s033',\n",
       "  'd001.s034',\n",
       "  'd001.s035',\n",
       "  'd001.s036',\n",
       "  'd001.s048',\n",
       "  'd001.s049',\n",
       "  'd001.s090'],\n",
       " 'd001.s033': ['d001.s018',\n",
       "  'd001.s029',\n",
       "  'd001.s030',\n",
       "  'd001.s031',\n",
       "  'd001.s032',\n",
       "  'd001.s033',\n",
       "  'd001.s034',\n",
       "  'd001.s035',\n",
       "  'd001.s036',\n",
       "  'd001.s037',\n",
       "  'd001.s049',\n",
       "  'd001.s135'],\n",
       " 'd001.s034': ['d001.s030',\n",
       "  'd001.s031',\n",
       "  'd001.s032',\n",
       "  'd001.s033',\n",
       "  'd001.s034',\n",
       "  'd001.s035',\n",
       "  'd001.s036',\n",
       "  'd001.s037',\n",
       "  'd001.s038',\n",
       "  'd001.s040',\n",
       "  'd001.s049',\n",
       "  'd001.s057'],\n",
       " 'd001.s035': ['d001.s000',\n",
       "  'd001.s001',\n",
       "  'd001.s002',\n",
       "  'd001.s003',\n",
       "  'd001.s031',\n",
       "  'd001.s032',\n",
       "  'd001.s033',\n",
       "  'd001.s034',\n",
       "  'd001.s035',\n",
       "  'd001.s036',\n",
       "  'd001.s037',\n",
       "  'd001.s038',\n",
       "  'd001.s039'],\n",
       " 'd001.s036': ['d001.s018',\n",
       "  'd001.s032',\n",
       "  'd001.s033',\n",
       "  'd001.s034',\n",
       "  'd001.s035',\n",
       "  'd001.s036',\n",
       "  'd001.s037',\n",
       "  'd001.s038',\n",
       "  'd001.s039',\n",
       "  'd001.s040',\n",
       "  'd001.s049',\n",
       "  'd001.s057'],\n",
       " 'd001.s037': ['d001.s033',\n",
       "  'd001.s034',\n",
       "  'd001.s035',\n",
       "  'd001.s036',\n",
       "  'd001.s037',\n",
       "  'd001.s038',\n",
       "  'd001.s039',\n",
       "  'd001.s040',\n",
       "  'd001.s041',\n",
       "  'd001.s094',\n",
       "  'd001.s096',\n",
       "  'd001.s115',\n",
       "  'd001.s131'],\n",
       " 'd001.s038': ['d001.s018',\n",
       "  'd001.s033',\n",
       "  'd001.s034',\n",
       "  'd001.s035',\n",
       "  'd001.s036',\n",
       "  'd001.s037',\n",
       "  'd001.s038',\n",
       "  'd001.s039',\n",
       "  'd001.s040',\n",
       "  'd001.s041',\n",
       "  'd001.s042',\n",
       "  'd001.s048',\n",
       "  'd001.s114'],\n",
       " 'd001.s039': ['d001.s035',\n",
       "  'd001.s036',\n",
       "  'd001.s037',\n",
       "  'd001.s038',\n",
       "  'd001.s039',\n",
       "  'd001.s040',\n",
       "  'd001.s041',\n",
       "  'd001.s042',\n",
       "  'd001.s043',\n",
       "  'd001.s048',\n",
       "  'd001.s049',\n",
       "  'd001.s082',\n",
       "  'd001.s090'],\n",
       " 'd001.s040': ['d001.s004',\n",
       "  'd001.s034',\n",
       "  'd001.s036',\n",
       "  'd001.s037',\n",
       "  'd001.s038',\n",
       "  'd001.s039',\n",
       "  'd001.s040',\n",
       "  'd001.s041',\n",
       "  'd001.s042',\n",
       "  'd001.s043',\n",
       "  'd001.s044',\n",
       "  'd001.s049',\n",
       "  'd001.s134'],\n",
       " 'd001.s041': ['d001.s033',\n",
       "  'd001.s037',\n",
       "  'd001.s038',\n",
       "  'd001.s039',\n",
       "  'd001.s040',\n",
       "  'd001.s041',\n",
       "  'd001.s042',\n",
       "  'd001.s043',\n",
       "  'd001.s044',\n",
       "  'd001.s045',\n",
       "  'd001.s049',\n",
       "  'd001.s132'],\n",
       " 'd001.s042': ['d001.s038',\n",
       "  'd001.s039',\n",
       "  'd001.s040',\n",
       "  'd001.s041',\n",
       "  'd001.s042',\n",
       "  'd001.s043',\n",
       "  'd001.s044',\n",
       "  'd001.s045',\n",
       "  'd001.s046',\n",
       "  'd001.s049',\n",
       "  'd001.s133',\n",
       "  'd001.s135'],\n",
       " 'd001.s043': ['d001.s039',\n",
       "  'd001.s040',\n",
       "  'd001.s041',\n",
       "  'd001.s042',\n",
       "  'd001.s043',\n",
       "  'd001.s044',\n",
       "  'd001.s045',\n",
       "  'd001.s046',\n",
       "  'd001.s047',\n",
       "  'd001.s056',\n",
       "  'd001.s057',\n",
       "  'd001.s109',\n",
       "  'd001.s125'],\n",
       " 'd001.s044': ['d001.s040',\n",
       "  'd001.s041',\n",
       "  'd001.s042',\n",
       "  'd001.s043',\n",
       "  'd001.s044',\n",
       "  'd001.s045',\n",
       "  'd001.s046',\n",
       "  'd001.s047',\n",
       "  'd001.s048',\n",
       "  'd001.s067',\n",
       "  'd001.s080',\n",
       "  'd001.s098',\n",
       "  'd001.s100'],\n",
       " 'd001.s045': ['d001.s003',\n",
       "  'd001.s020',\n",
       "  'd001.s041',\n",
       "  'd001.s042',\n",
       "  'd001.s043',\n",
       "  'd001.s044',\n",
       "  'd001.s045',\n",
       "  'd001.s046',\n",
       "  'd001.s047',\n",
       "  'd001.s048',\n",
       "  'd001.s049',\n",
       "  'd001.s090'],\n",
       " 'd001.s046': ['d001.s042',\n",
       "  'd001.s043',\n",
       "  'd001.s044',\n",
       "  'd001.s045',\n",
       "  'd001.s046',\n",
       "  'd001.s047',\n",
       "  'd001.s048',\n",
       "  'd001.s049',\n",
       "  'd001.s050',\n",
       "  'd001.s082',\n",
       "  'd001.s090'],\n",
       " 'd001.s047': ['d001.s033',\n",
       "  'd001.s043',\n",
       "  'd001.s044',\n",
       "  'd001.s045',\n",
       "  'd001.s046',\n",
       "  'd001.s047',\n",
       "  'd001.s048',\n",
       "  'd001.s049',\n",
       "  'd001.s050',\n",
       "  'd001.s051',\n",
       "  'd001.s052',\n",
       "  'd001.s090'],\n",
       " 'd001.s048': ['d001.s015',\n",
       "  'd001.s018',\n",
       "  'd001.s033',\n",
       "  'd001.s044',\n",
       "  'd001.s045',\n",
       "  'd001.s046',\n",
       "  'd001.s047',\n",
       "  'd001.s048',\n",
       "  'd001.s049',\n",
       "  'd001.s050',\n",
       "  'd001.s051',\n",
       "  'd001.s052'],\n",
       " 'd001.s049': ['d001.s033',\n",
       "  'd001.s040',\n",
       "  'd001.s045',\n",
       "  'd001.s046',\n",
       "  'd001.s047',\n",
       "  'd001.s048',\n",
       "  'd001.s049',\n",
       "  'd001.s050',\n",
       "  'd001.s051',\n",
       "  'd001.s052',\n",
       "  'd001.s053',\n",
       "  'd001.s091',\n",
       "  'd001.s131'],\n",
       " 'd001.s050': ['d001.s033',\n",
       "  'd001.s040',\n",
       "  'd001.s046',\n",
       "  'd001.s047',\n",
       "  'd001.s048',\n",
       "  'd001.s049',\n",
       "  'd001.s050',\n",
       "  'd001.s051',\n",
       "  'd001.s052',\n",
       "  'd001.s053',\n",
       "  'd001.s054',\n",
       "  'd001.s070'],\n",
       " 'd001.s051': ['d001.s033',\n",
       "  'd001.s040',\n",
       "  'd001.s047',\n",
       "  'd001.s048',\n",
       "  'd001.s049',\n",
       "  'd001.s050',\n",
       "  'd001.s051',\n",
       "  'd001.s052',\n",
       "  'd001.s053',\n",
       "  'd001.s054',\n",
       "  'd001.s055'],\n",
       " 'd001.s052': ['d001.s048',\n",
       "  'd001.s049',\n",
       "  'd001.s050',\n",
       "  'd001.s051',\n",
       "  'd001.s052',\n",
       "  'd001.s053',\n",
       "  'd001.s054',\n",
       "  'd001.s055',\n",
       "  'd001.s056',\n",
       "  'd001.s065',\n",
       "  'd001.s090',\n",
       "  'd001.s097',\n",
       "  'd001.s120'],\n",
       " 'd001.s053': ['d001.s049',\n",
       "  'd001.s050',\n",
       "  'd001.s051',\n",
       "  'd001.s052',\n",
       "  'd001.s053',\n",
       "  'd001.s054',\n",
       "  'd001.s055',\n",
       "  'd001.s056',\n",
       "  'd001.s057',\n",
       "  'd001.s063',\n",
       "  'd001.s090',\n",
       "  'd001.s124',\n",
       "  'd001.s126'],\n",
       " 'd001.s054': ['d001.s049',\n",
       "  'd001.s050',\n",
       "  'd001.s051',\n",
       "  'd001.s052',\n",
       "  'd001.s053',\n",
       "  'd001.s054',\n",
       "  'd001.s055',\n",
       "  'd001.s056',\n",
       "  'd001.s057',\n",
       "  'd001.s058',\n",
       "  'd001.s092',\n",
       "  'd001.s133'],\n",
       " 'd001.s055': ['d001.s042',\n",
       "  'd001.s048',\n",
       "  'd001.s051',\n",
       "  'd001.s052',\n",
       "  'd001.s053',\n",
       "  'd001.s054',\n",
       "  'd001.s055',\n",
       "  'd001.s056',\n",
       "  'd001.s057',\n",
       "  'd001.s058',\n",
       "  'd001.s059',\n",
       "  'd001.s133'],\n",
       " 'd001.s056': ['d001.s033',\n",
       "  'd001.s040',\n",
       "  'd001.s049',\n",
       "  'd001.s052',\n",
       "  'd001.s053',\n",
       "  'd001.s054',\n",
       "  'd001.s055',\n",
       "  'd001.s056',\n",
       "  'd001.s057',\n",
       "  'd001.s058',\n",
       "  'd001.s059',\n",
       "  'd001.s060',\n",
       "  'd001.s118'],\n",
       " 'd001.s057': ['d001.s033',\n",
       "  'd001.s048',\n",
       "  'd001.s049',\n",
       "  'd001.s053',\n",
       "  'd001.s054',\n",
       "  'd001.s055',\n",
       "  'd001.s056',\n",
       "  'd001.s057',\n",
       "  'd001.s058',\n",
       "  'd001.s059',\n",
       "  'd001.s060',\n",
       "  'd001.s061',\n",
       "  'd001.s073'],\n",
       " 'd001.s058': ['d001.s034',\n",
       "  'd001.s054',\n",
       "  'd001.s055',\n",
       "  'd001.s056',\n",
       "  'd001.s057',\n",
       "  'd001.s058',\n",
       "  'd001.s059',\n",
       "  'd001.s060',\n",
       "  'd001.s061',\n",
       "  'd001.s062',\n",
       "  'd001.s090',\n",
       "  'd001.s111'],\n",
       " 'd001.s059': ['d001.s048',\n",
       "  'd001.s055',\n",
       "  'd001.s056',\n",
       "  'd001.s057',\n",
       "  'd001.s058',\n",
       "  'd001.s059',\n",
       "  'd001.s060',\n",
       "  'd001.s061',\n",
       "  'd001.s062',\n",
       "  'd001.s063',\n",
       "  'd001.s073',\n",
       "  'd001.s079',\n",
       "  'd001.s131'],\n",
       " 'd001.s060': ['d001.s048',\n",
       "  'd001.s049',\n",
       "  'd001.s056',\n",
       "  'd001.s057',\n",
       "  'd001.s058',\n",
       "  'd001.s059',\n",
       "  'd001.s060',\n",
       "  'd001.s061',\n",
       "  'd001.s062',\n",
       "  'd001.s063',\n",
       "  'd001.s065',\n",
       "  'd001.s082',\n",
       "  'd001.s090'],\n",
       " 'd001.s061': ['d001.s047',\n",
       "  'd001.s057',\n",
       "  'd001.s058',\n",
       "  'd001.s059',\n",
       "  'd001.s060',\n",
       "  'd001.s061',\n",
       "  'd001.s062',\n",
       "  'd001.s063',\n",
       "  'd001.s065',\n",
       "  'd001.s066',\n",
       "  'd001.s075',\n",
       "  'd001.s118',\n",
       "  'd001.s130'],\n",
       " 'd001.s062': ['d001.s000',\n",
       "  'd001.s001',\n",
       "  'd001.s002',\n",
       "  'd001.s003',\n",
       "  'd001.s058',\n",
       "  'd001.s059',\n",
       "  'd001.s060',\n",
       "  'd001.s061',\n",
       "  'd001.s062',\n",
       "  'd001.s063',\n",
       "  'd001.s065',\n",
       "  'd001.s066',\n",
       "  'd001.s067'],\n",
       " 'd001.s063': ['d001.s016',\n",
       "  'd001.s033',\n",
       "  'd001.s049',\n",
       "  'd001.s059',\n",
       "  'd001.s060',\n",
       "  'd001.s061',\n",
       "  'd001.s062',\n",
       "  'd001.s063',\n",
       "  'd001.s065',\n",
       "  'd001.s066',\n",
       "  'd001.s067',\n",
       "  'd001.s068',\n",
       "  'd001.s135'],\n",
       " 'd001.s065': ['d001.s029',\n",
       "  'd001.s052',\n",
       "  'd001.s060',\n",
       "  'd001.s061',\n",
       "  'd001.s062',\n",
       "  'd001.s063',\n",
       "  'd001.s065',\n",
       "  'd001.s066',\n",
       "  'd001.s067',\n",
       "  'd001.s068',\n",
       "  'd001.s069',\n",
       "  'd001.s120',\n",
       "  'd001.s134'],\n",
       " 'd001.s066': ['d001.s000',\n",
       "  'd001.s001',\n",
       "  'd001.s002',\n",
       "  'd001.s061',\n",
       "  'd001.s062',\n",
       "  'd001.s063',\n",
       "  'd001.s065',\n",
       "  'd001.s066',\n",
       "  'd001.s067',\n",
       "  'd001.s068',\n",
       "  'd001.s069',\n",
       "  'd001.s070',\n",
       "  'd001.s081'],\n",
       " 'd001.s067': ['d001.s044',\n",
       "  'd001.s062',\n",
       "  'd001.s063',\n",
       "  'd001.s065',\n",
       "  'd001.s066',\n",
       "  'd001.s067',\n",
       "  'd001.s068',\n",
       "  'd001.s069',\n",
       "  'd001.s070',\n",
       "  'd001.s071',\n",
       "  'd001.s080',\n",
       "  'd001.s100'],\n",
       " 'd001.s068': ['d001.s029',\n",
       "  'd001.s063',\n",
       "  'd001.s065',\n",
       "  'd001.s066',\n",
       "  'd001.s067',\n",
       "  'd001.s068',\n",
       "  'd001.s069',\n",
       "  'd001.s070',\n",
       "  'd001.s071',\n",
       "  'd001.s072',\n",
       "  'd001.s093'],\n",
       " 'd001.s069': ['d001.s048',\n",
       "  'd001.s049',\n",
       "  'd001.s065',\n",
       "  'd001.s066',\n",
       "  'd001.s067',\n",
       "  'd001.s068',\n",
       "  'd001.s069',\n",
       "  'd001.s070',\n",
       "  'd001.s071',\n",
       "  'd001.s072',\n",
       "  'd001.s073',\n",
       "  'd001.s082',\n",
       "  'd001.s090'],\n",
       " 'd001.s070': ['d001.s048',\n",
       "  'd001.s049',\n",
       "  'd001.s050',\n",
       "  'd001.s066',\n",
       "  'd001.s067',\n",
       "  'd001.s068',\n",
       "  'd001.s069',\n",
       "  'd001.s070',\n",
       "  'd001.s071',\n",
       "  'd001.s072',\n",
       "  'd001.s073',\n",
       "  'd001.s074',\n",
       "  'd001.s090'],\n",
       " 'd001.s071': ['d001.s001',\n",
       "  'd001.s018',\n",
       "  'd001.s033',\n",
       "  'd001.s048',\n",
       "  'd001.s067',\n",
       "  'd001.s068',\n",
       "  'd001.s069',\n",
       "  'd001.s070',\n",
       "  'd001.s071',\n",
       "  'd001.s072',\n",
       "  'd001.s073',\n",
       "  'd001.s074',\n",
       "  'd001.s075'],\n",
       " 'd001.s072': ['d001.s048',\n",
       "  'd001.s057',\n",
       "  'd001.s068',\n",
       "  'd001.s069',\n",
       "  'd001.s070',\n",
       "  'd001.s071',\n",
       "  'd001.s072',\n",
       "  'd001.s073',\n",
       "  'd001.s074',\n",
       "  'd001.s075',\n",
       "  'd001.s076'],\n",
       " 'd001.s073': ['d001.s014',\n",
       "  'd001.s048',\n",
       "  'd001.s057',\n",
       "  'd001.s059',\n",
       "  'd001.s069',\n",
       "  'd001.s070',\n",
       "  'd001.s071',\n",
       "  'd001.s072',\n",
       "  'd001.s073',\n",
       "  'd001.s074',\n",
       "  'd001.s075',\n",
       "  'd001.s076',\n",
       "  'd001.s077'],\n",
       " 'd001.s074': ['d001.s000',\n",
       "  'd001.s001',\n",
       "  'd001.s002',\n",
       "  'd001.s003',\n",
       "  'd001.s070',\n",
       "  'd001.s071',\n",
       "  'd001.s072',\n",
       "  'd001.s073',\n",
       "  'd001.s074',\n",
       "  'd001.s075',\n",
       "  'd001.s076',\n",
       "  'd001.s077',\n",
       "  'd001.s078'],\n",
       " 'd001.s075': ['d001.s016',\n",
       "  'd001.s061',\n",
       "  'd001.s071',\n",
       "  'd001.s072',\n",
       "  'd001.s073',\n",
       "  'd001.s074',\n",
       "  'd001.s075',\n",
       "  'd001.s076',\n",
       "  'd001.s077',\n",
       "  'd001.s078',\n",
       "  'd001.s079',\n",
       "  'd001.s118',\n",
       "  'd001.s130'],\n",
       " 'd001.s076': ['d001.s048',\n",
       "  'd001.s049',\n",
       "  'd001.s072',\n",
       "  'd001.s073',\n",
       "  'd001.s074',\n",
       "  'd001.s075',\n",
       "  'd001.s076',\n",
       "  'd001.s077',\n",
       "  'd001.s078',\n",
       "  'd001.s079',\n",
       "  'd001.s080',\n",
       "  'd001.s082',\n",
       "  'd001.s090'],\n",
       " 'd001.s077': ['d001.s000',\n",
       "  'd001.s001',\n",
       "  'd001.s002',\n",
       "  'd001.s003',\n",
       "  'd001.s073',\n",
       "  'd001.s074',\n",
       "  'd001.s075',\n",
       "  'd001.s076',\n",
       "  'd001.s077',\n",
       "  'd001.s078',\n",
       "  'd001.s079',\n",
       "  'd001.s080',\n",
       "  'd001.s081'],\n",
       " 'd001.s078': ['d001.s016',\n",
       "  'd001.s033',\n",
       "  'd001.s040',\n",
       "  'd001.s049',\n",
       "  'd001.s074',\n",
       "  'd001.s075',\n",
       "  'd001.s076',\n",
       "  'd001.s077',\n",
       "  'd001.s078',\n",
       "  'd001.s079',\n",
       "  'd001.s080',\n",
       "  'd001.s081',\n",
       "  'd001.s082'],\n",
       " 'd001.s079': ['d001.s059',\n",
       "  'd001.s063',\n",
       "  'd001.s075',\n",
       "  'd001.s076',\n",
       "  'd001.s077',\n",
       "  'd001.s078',\n",
       "  'd001.s079',\n",
       "  'd001.s080',\n",
       "  'd001.s081',\n",
       "  'd001.s082',\n",
       "  'd001.s083',\n",
       "  'd001.s090',\n",
       "  'd001.s093'],\n",
       " 'd001.s080': ['d001.s027',\n",
       "  'd001.s032',\n",
       "  'd001.s067',\n",
       "  'd001.s076',\n",
       "  'd001.s077',\n",
       "  'd001.s078',\n",
       "  'd001.s079',\n",
       "  'd001.s080',\n",
       "  'd001.s081',\n",
       "  'd001.s082',\n",
       "  'd001.s083',\n",
       "  'd001.s084',\n",
       "  'd001.s100'],\n",
       " 'd001.s081': ['d001.s038',\n",
       "  'd001.s048',\n",
       "  'd001.s077',\n",
       "  'd001.s078',\n",
       "  'd001.s079',\n",
       "  'd001.s080',\n",
       "  'd001.s081',\n",
       "  'd001.s082',\n",
       "  'd001.s083',\n",
       "  'd001.s084',\n",
       "  'd001.s085',\n",
       "  'd001.s103',\n",
       "  'd001.s131'],\n",
       " 'd001.s082': ['d001.s048',\n",
       "  'd001.s049',\n",
       "  'd001.s078',\n",
       "  'd001.s079',\n",
       "  'd001.s080',\n",
       "  'd001.s081',\n",
       "  'd001.s082',\n",
       "  'd001.s083',\n",
       "  'd001.s084',\n",
       "  'd001.s085',\n",
       "  'd001.s086',\n",
       "  'd001.s090',\n",
       "  'd001.s106'],\n",
       " 'd001.s083': ['d001.s055',\n",
       "  'd001.s079',\n",
       "  'd001.s080',\n",
       "  'd001.s081',\n",
       "  'd001.s082',\n",
       "  'd001.s083',\n",
       "  'd001.s084',\n",
       "  'd001.s085',\n",
       "  'd001.s086',\n",
       "  'd001.s087'],\n",
       " 'd001.s084': ['d001.s000',\n",
       "  'd001.s001',\n",
       "  'd001.s005',\n",
       "  'd001.s080',\n",
       "  'd001.s081',\n",
       "  'd001.s082',\n",
       "  'd001.s083',\n",
       "  'd001.s084',\n",
       "  'd001.s085',\n",
       "  'd001.s086',\n",
       "  'd001.s087',\n",
       "  'd001.s088',\n",
       "  'd001.s106'],\n",
       " 'd001.s085': ['d001.s056',\n",
       "  'd001.s081',\n",
       "  'd001.s082',\n",
       "  'd001.s083',\n",
       "  'd001.s084',\n",
       "  'd001.s085',\n",
       "  'd001.s086',\n",
       "  'd001.s087',\n",
       "  'd001.s088',\n",
       "  'd001.s089',\n",
       "  'd001.s091',\n",
       "  'd001.s116'],\n",
       " 'd001.s086': ['d001.s029',\n",
       "  'd001.s082',\n",
       "  'd001.s083',\n",
       "  'd001.s084',\n",
       "  'd001.s085',\n",
       "  'd001.s086',\n",
       "  'd001.s087',\n",
       "  'd001.s088',\n",
       "  'd001.s089',\n",
       "  'd001.s090',\n",
       "  'd001.s116',\n",
       "  'd001.s135'],\n",
       " 'd001.s087': ['d001.s049',\n",
       "  'd001.s071',\n",
       "  'd001.s072',\n",
       "  'd001.s083',\n",
       "  'd001.s084',\n",
       "  'd001.s085',\n",
       "  'd001.s086',\n",
       "  'd001.s087',\n",
       "  'd001.s088',\n",
       "  'd001.s089',\n",
       "  'd001.s090',\n",
       "  'd001.s091'],\n",
       " 'd001.s088': ['d001.s048',\n",
       "  'd001.s049',\n",
       "  'd001.s084',\n",
       "  'd001.s085',\n",
       "  'd001.s086',\n",
       "  'd001.s087',\n",
       "  'd001.s088',\n",
       "  'd001.s089',\n",
       "  'd001.s090',\n",
       "  'd001.s091',\n",
       "  'd001.s092',\n",
       "  'd001.s124'],\n",
       " 'd001.s089': ['d001.s049',\n",
       "  'd001.s085',\n",
       "  'd001.s086',\n",
       "  'd001.s087',\n",
       "  'd001.s088',\n",
       "  'd001.s089',\n",
       "  'd001.s090',\n",
       "  'd001.s091',\n",
       "  'd001.s092',\n",
       "  'd001.s093',\n",
       "  'd001.s116'],\n",
       " 'd001.s090': ['d001.s049',\n",
       "  'd001.s086',\n",
       "  'd001.s087',\n",
       "  'd001.s088',\n",
       "  'd001.s089',\n",
       "  'd001.s090',\n",
       "  'd001.s091',\n",
       "  'd001.s092',\n",
       "  'd001.s093',\n",
       "  'd001.s094',\n",
       "  'd001.s104',\n",
       "  'd001.s118'],\n",
       " 'd001.s091': ['d001.s033',\n",
       "  'd001.s040',\n",
       "  'd001.s049',\n",
       "  'd001.s051',\n",
       "  'd001.s087',\n",
       "  'd001.s088',\n",
       "  'd001.s089',\n",
       "  'd001.s090',\n",
       "  'd001.s091',\n",
       "  'd001.s092',\n",
       "  'd001.s093',\n",
       "  'd001.s094',\n",
       "  'd001.s095'],\n",
       " 'd001.s092': ['d001.s049',\n",
       "  'd001.s088',\n",
       "  'd001.s089',\n",
       "  'd001.s090',\n",
       "  'd001.s091',\n",
       "  'd001.s092',\n",
       "  'd001.s093',\n",
       "  'd001.s094',\n",
       "  'd001.s095',\n",
       "  'd001.s096',\n",
       "  'd001.s106',\n",
       "  'd001.s112'],\n",
       " 'd001.s093': ['d001.s063',\n",
       "  'd001.s065',\n",
       "  'd001.s068',\n",
       "  'd001.s089',\n",
       "  'd001.s090',\n",
       "  'd001.s091',\n",
       "  'd001.s092',\n",
       "  'd001.s093',\n",
       "  'd001.s094',\n",
       "  'd001.s095',\n",
       "  'd001.s096',\n",
       "  'd001.s097',\n",
       "  'd001.s134'],\n",
       " 'd001.s094': ['d001.s037',\n",
       "  'd001.s048',\n",
       "  'd001.s049',\n",
       "  'd001.s090',\n",
       "  'd001.s091',\n",
       "  'd001.s092',\n",
       "  'd001.s093',\n",
       "  'd001.s094',\n",
       "  'd001.s095',\n",
       "  'd001.s096',\n",
       "  'd001.s097',\n",
       "  'd001.s098'],\n",
       " 'd001.s095': ['d001.s052',\n",
       "  'd001.s065',\n",
       "  'd001.s091',\n",
       "  'd001.s092',\n",
       "  'd001.s093',\n",
       "  'd001.s094',\n",
       "  'd001.s095',\n",
       "  'd001.s096',\n",
       "  'd001.s097',\n",
       "  'd001.s098',\n",
       "  'd001.s099',\n",
       "  'd001.s120'],\n",
       " 'd001.s096': ['d001.s000',\n",
       "  'd001.s037',\n",
       "  'd001.s051',\n",
       "  'd001.s080',\n",
       "  'd001.s092',\n",
       "  'd001.s093',\n",
       "  'd001.s094',\n",
       "  'd001.s095',\n",
       "  'd001.s096',\n",
       "  'd001.s097',\n",
       "  'd001.s098',\n",
       "  'd001.s099',\n",
       "  'd001.s100'],\n",
       " 'd001.s097': ['d001.s018',\n",
       "  'd001.s033',\n",
       "  'd001.s048',\n",
       "  'd001.s052',\n",
       "  'd001.s093',\n",
       "  'd001.s094',\n",
       "  'd001.s095',\n",
       "  'd001.s096',\n",
       "  'd001.s097',\n",
       "  'd001.s098',\n",
       "  'd001.s099',\n",
       "  'd001.s100',\n",
       "  'd001.s101'],\n",
       " 'd001.s098': ['d001.s052',\n",
       "  'd001.s056',\n",
       "  'd001.s057',\n",
       "  'd001.s094',\n",
       "  'd001.s095',\n",
       "  'd001.s096',\n",
       "  'd001.s097',\n",
       "  'd001.s098',\n",
       "  'd001.s099',\n",
       "  'd001.s100',\n",
       "  'd001.s101',\n",
       "  'd001.s102'],\n",
       " 'd001.s099': ['d001.s093',\n",
       "  'd001.s095',\n",
       "  'd001.s096',\n",
       "  'd001.s097',\n",
       "  'd001.s098',\n",
       "  'd001.s099',\n",
       "  'd001.s100',\n",
       "  'd001.s101',\n",
       "  'd001.s102',\n",
       "  'd001.s103',\n",
       "  'd001.s109',\n",
       "  'd001.s117'],\n",
       " 'd001.s100': ['d001.s044',\n",
       "  'd001.s067',\n",
       "  'd001.s096',\n",
       "  'd001.s097',\n",
       "  'd001.s098',\n",
       "  'd001.s099',\n",
       "  'd001.s100',\n",
       "  'd001.s101',\n",
       "  'd001.s102',\n",
       "  'd001.s103',\n",
       "  'd001.s104'],\n",
       " 'd001.s101': ['d001.s048',\n",
       "  'd001.s049',\n",
       "  'd001.s090',\n",
       "  'd001.s097',\n",
       "  'd001.s098',\n",
       "  'd001.s099',\n",
       "  'd001.s100',\n",
       "  'd001.s101',\n",
       "  'd001.s102',\n",
       "  'd001.s103',\n",
       "  'd001.s104',\n",
       "  'd001.s105'],\n",
       " 'd001.s102': ['d001.s022',\n",
       "  'd001.s057',\n",
       "  'd001.s093',\n",
       "  'd001.s098',\n",
       "  'd001.s099',\n",
       "  'd001.s100',\n",
       "  'd001.s101',\n",
       "  'd001.s102',\n",
       "  'd001.s103',\n",
       "  'd001.s104',\n",
       "  'd001.s105',\n",
       "  'd001.s106'],\n",
       " 'd001.s103': ['d001.s033',\n",
       "  'd001.s040',\n",
       "  'd001.s049',\n",
       "  'd001.s091',\n",
       "  'd001.s099',\n",
       "  'd001.s100',\n",
       "  'd001.s101',\n",
       "  'd001.s102',\n",
       "  'd001.s103',\n",
       "  'd001.s104',\n",
       "  'd001.s105',\n",
       "  'd001.s106',\n",
       "  'd001.s107'],\n",
       " 'd001.s104': ['d001.s000',\n",
       "  'd001.s081',\n",
       "  'd001.s086',\n",
       "  'd001.s090',\n",
       "  'd001.s100',\n",
       "  'd001.s101',\n",
       "  'd001.s102',\n",
       "  'd001.s103',\n",
       "  'd001.s104',\n",
       "  'd001.s105',\n",
       "  'd001.s106',\n",
       "  'd001.s107',\n",
       "  'd001.s108'],\n",
       " 'd001.s105': ['d001.s000',\n",
       "  'd001.s001',\n",
       "  'd001.s002',\n",
       "  'd001.s101',\n",
       "  'd001.s102',\n",
       "  'd001.s103',\n",
       "  'd001.s104',\n",
       "  'd001.s105',\n",
       "  'd001.s106',\n",
       "  'd001.s107',\n",
       "  'd001.s108',\n",
       "  'd001.s109',\n",
       "  'd001.s125'],\n",
       " 'd001.s106': ['d001.s048',\n",
       "  'd001.s049',\n",
       "  'd001.s051',\n",
       "  'd001.s056',\n",
       "  'd001.s102',\n",
       "  'd001.s103',\n",
       "  'd001.s104',\n",
       "  'd001.s105',\n",
       "  'd001.s106',\n",
       "  'd001.s107',\n",
       "  'd001.s108',\n",
       "  'd001.s109',\n",
       "  'd001.s110'],\n",
       " 'd001.s107': ['d001.s031',\n",
       "  'd001.s034',\n",
       "  'd001.s103',\n",
       "  'd001.s104',\n",
       "  'd001.s105',\n",
       "  'd001.s106',\n",
       "  'd001.s107',\n",
       "  'd001.s108',\n",
       "  'd001.s109',\n",
       "  'd001.s110',\n",
       "  'd001.s111',\n",
       "  'd001.s126'],\n",
       " 'd001.s108': ['d001.s048',\n",
       "  'd001.s049',\n",
       "  'd001.s090',\n",
       "  'd001.s104',\n",
       "  'd001.s105',\n",
       "  'd001.s106',\n",
       "  'd001.s107',\n",
       "  'd001.s108',\n",
       "  'd001.s109',\n",
       "  'd001.s110',\n",
       "  'd001.s111',\n",
       "  'd001.s112',\n",
       "  'd001.s131'],\n",
       " 'd001.s109': ['d001.s001',\n",
       "  'd001.s012',\n",
       "  'd001.s018',\n",
       "  'd001.s033',\n",
       "  'd001.s105',\n",
       "  'd001.s106',\n",
       "  'd001.s107',\n",
       "  'd001.s108',\n",
       "  'd001.s109',\n",
       "  'd001.s110',\n",
       "  'd001.s111',\n",
       "  'd001.s112',\n",
       "  'd001.s113'],\n",
       " 'd001.s110': ['d001.s042',\n",
       "  'd001.s106',\n",
       "  'd001.s107',\n",
       "  'd001.s108',\n",
       "  'd001.s109',\n",
       "  'd001.s110',\n",
       "  'd001.s111',\n",
       "  'd001.s112',\n",
       "  'd001.s113',\n",
       "  'd001.s114',\n",
       "  'd001.s129',\n",
       "  'd001.s135'],\n",
       " 'd001.s111': ['d001.s004',\n",
       "  'd001.s033',\n",
       "  'd001.s040',\n",
       "  'd001.s049',\n",
       "  'd001.s107',\n",
       "  'd001.s108',\n",
       "  'd001.s109',\n",
       "  'd001.s110',\n",
       "  'd001.s111',\n",
       "  'd001.s112',\n",
       "  'd001.s113',\n",
       "  'd001.s114',\n",
       "  'd001.s115'],\n",
       " 'd001.s112': ['d001.s029',\n",
       "  'd001.s090',\n",
       "  'd001.s092',\n",
       "  'd001.s108',\n",
       "  'd001.s109',\n",
       "  'd001.s110',\n",
       "  'd001.s111',\n",
       "  'd001.s112',\n",
       "  'd001.s113',\n",
       "  'd001.s114',\n",
       "  'd001.s115',\n",
       "  'd001.s116',\n",
       "  'd001.s131'],\n",
       " 'd001.s113': ['d001.s048',\n",
       "  'd001.s051',\n",
       "  'd001.s056',\n",
       "  'd001.s090',\n",
       "  'd001.s109',\n",
       "  'd001.s110',\n",
       "  'd001.s111',\n",
       "  'd001.s112',\n",
       "  'd001.s113',\n",
       "  'd001.s114',\n",
       "  'd001.s115',\n",
       "  'd001.s116',\n",
       "  'd001.s117'],\n",
       " 'd001.s114': ['d001.s038',\n",
       "  'd001.s040',\n",
       "  'd001.s042',\n",
       "  'd001.s110',\n",
       "  'd001.s111',\n",
       "  'd001.s112',\n",
       "  'd001.s113',\n",
       "  'd001.s114',\n",
       "  'd001.s115',\n",
       "  'd001.s116',\n",
       "  'd001.s117',\n",
       "  'd001.s118',\n",
       "  'd001.s135'],\n",
       " 'd001.s115': ['d001.s000',\n",
       "  'd001.s001',\n",
       "  'd001.s037',\n",
       "  'd001.s111',\n",
       "  'd001.s112',\n",
       "  'd001.s113',\n",
       "  'd001.s114',\n",
       "  'd001.s115',\n",
       "  'd001.s116',\n",
       "  'd001.s117',\n",
       "  'd001.s118',\n",
       "  'd001.s119'],\n",
       " 'd001.s116': ['d001.s000',\n",
       "  'd001.s085',\n",
       "  'd001.s086',\n",
       "  'd001.s089',\n",
       "  'd001.s112',\n",
       "  'd001.s113',\n",
       "  'd001.s114',\n",
       "  'd001.s115',\n",
       "  'd001.s116',\n",
       "  'd001.s117',\n",
       "  'd001.s118',\n",
       "  'd001.s119',\n",
       "  'd001.s120'],\n",
       " 'd001.s117': ['d001.s033',\n",
       "  'd001.s034',\n",
       "  'd001.s109',\n",
       "  'd001.s113',\n",
       "  'd001.s114',\n",
       "  'd001.s115',\n",
       "  'd001.s116',\n",
       "  'd001.s117',\n",
       "  'd001.s118',\n",
       "  'd001.s119',\n",
       "  'd001.s120',\n",
       "  'd001.s121'],\n",
       " 'd001.s118': ['d001.s033',\n",
       "  'd001.s056',\n",
       "  'd001.s090',\n",
       "  'd001.s114',\n",
       "  'd001.s115',\n",
       "  'd001.s116',\n",
       "  'd001.s117',\n",
       "  'd001.s118',\n",
       "  'd001.s119',\n",
       "  'd001.s120',\n",
       "  'd001.s121',\n",
       "  'd001.s122',\n",
       "  'd001.s130'],\n",
       " 'd001.s119': ['d001.s014',\n",
       "  'd001.s020',\n",
       "  'd001.s065',\n",
       "  'd001.s090',\n",
       "  'd001.s115',\n",
       "  'd001.s116',\n",
       "  'd001.s117',\n",
       "  'd001.s118',\n",
       "  'd001.s119',\n",
       "  'd001.s120',\n",
       "  'd001.s121',\n",
       "  'd001.s122',\n",
       "  'd001.s123'],\n",
       " 'd001.s120': ['d001.s052',\n",
       "  'd001.s065',\n",
       "  'd001.s090',\n",
       "  'd001.s097',\n",
       "  'd001.s116',\n",
       "  'd001.s117',\n",
       "  'd001.s118',\n",
       "  'd001.s119',\n",
       "  'd001.s120',\n",
       "  'd001.s121',\n",
       "  'd001.s122',\n",
       "  'd001.s123',\n",
       "  'd001.s124'],\n",
       " 'd001.s121': ['d001.s034',\n",
       "  'd001.s071',\n",
       "  'd001.s072',\n",
       "  'd001.s095',\n",
       "  'd001.s117',\n",
       "  'd001.s118',\n",
       "  'd001.s119',\n",
       "  'd001.s120',\n",
       "  'd001.s121',\n",
       "  'd001.s122',\n",
       "  'd001.s123',\n",
       "  'd001.s124',\n",
       "  'd001.s125'],\n",
       " 'd001.s122': ['d001.s047',\n",
       "  'd001.s048',\n",
       "  'd001.s118',\n",
       "  'd001.s119',\n",
       "  'd001.s120',\n",
       "  'd001.s121',\n",
       "  'd001.s122',\n",
       "  'd001.s123',\n",
       "  'd001.s124',\n",
       "  'd001.s125',\n",
       "  'd001.s126'],\n",
       " 'd001.s123': ['d001.s000',\n",
       "  'd001.s001',\n",
       "  'd001.s002',\n",
       "  'd001.s119',\n",
       "  'd001.s120',\n",
       "  'd001.s121',\n",
       "  'd001.s122',\n",
       "  'd001.s123',\n",
       "  'd001.s124',\n",
       "  'd001.s125',\n",
       "  'd001.s126',\n",
       "  'd001.s127'],\n",
       " 'd001.s124': ['d001.s049',\n",
       "  'd001.s053',\n",
       "  'd001.s088',\n",
       "  'd001.s090',\n",
       "  'd001.s120',\n",
       "  'd001.s121',\n",
       "  'd001.s122',\n",
       "  'd001.s123',\n",
       "  'd001.s124',\n",
       "  'd001.s125',\n",
       "  'd001.s126',\n",
       "  'd001.s127',\n",
       "  'd001.s128'],\n",
       " 'd001.s125': ['d001.s034',\n",
       "  'd001.s087',\n",
       "  'd001.s105',\n",
       "  'd001.s121',\n",
       "  'd001.s122',\n",
       "  'd001.s123',\n",
       "  'd001.s124',\n",
       "  'd001.s125',\n",
       "  'd001.s126',\n",
       "  'd001.s127',\n",
       "  'd001.s128',\n",
       "  'd001.s129'],\n",
       " 'd001.s126': ['d001.s049',\n",
       "  'd001.s053',\n",
       "  'd001.s090',\n",
       "  'd001.s122',\n",
       "  'd001.s123',\n",
       "  'd001.s124',\n",
       "  'd001.s125',\n",
       "  'd001.s126',\n",
       "  'd001.s127',\n",
       "  'd001.s128',\n",
       "  'd001.s129',\n",
       "  'd001.s130'],\n",
       " 'd001.s127': ['d001.s008',\n",
       "  'd001.s048',\n",
       "  'd001.s072',\n",
       "  'd001.s122',\n",
       "  'd001.s123',\n",
       "  'd001.s124',\n",
       "  'd001.s125',\n",
       "  'd001.s126',\n",
       "  'd001.s127',\n",
       "  'd001.s128',\n",
       "  'd001.s129',\n",
       "  'd001.s130',\n",
       "  'd001.s131'],\n",
       " 'd001.s128': ['d001.s000',\n",
       "  'd001.s001',\n",
       "  'd001.s002',\n",
       "  'd001.s003',\n",
       "  'd001.s124',\n",
       "  'd001.s125',\n",
       "  'd001.s126',\n",
       "  'd001.s127',\n",
       "  'd001.s128',\n",
       "  'd001.s129',\n",
       "  'd001.s130',\n",
       "  'd001.s131',\n",
       "  'd001.s132'],\n",
       " 'd001.s129': ['d001.s048',\n",
       "  'd001.s049',\n",
       "  'd001.s090',\n",
       "  'd001.s110',\n",
       "  'd001.s125',\n",
       "  'd001.s126',\n",
       "  'd001.s127',\n",
       "  'd001.s128',\n",
       "  'd001.s129',\n",
       "  'd001.s130',\n",
       "  'd001.s131',\n",
       "  'd001.s132',\n",
       "  'd001.s133'],\n",
       " 'd001.s130': ['d001.s000',\n",
       "  'd001.s061',\n",
       "  'd001.s075',\n",
       "  'd001.s118',\n",
       "  'd001.s126',\n",
       "  'd001.s127',\n",
       "  'd001.s128',\n",
       "  'd001.s129',\n",
       "  'd001.s130',\n",
       "  'd001.s131',\n",
       "  'd001.s132',\n",
       "  'd001.s133',\n",
       "  'd001.s134'],\n",
       " 'd001.s131': ['d001.s018',\n",
       "  'd001.s029',\n",
       "  'd001.s033',\n",
       "  'd001.s049',\n",
       "  'd001.s127',\n",
       "  'd001.s128',\n",
       "  'd001.s129',\n",
       "  'd001.s130',\n",
       "  'd001.s131',\n",
       "  'd001.s132',\n",
       "  'd001.s133',\n",
       "  'd001.s134',\n",
       "  'd001.s135'],\n",
       " 'd001.s132': ['d001.s041',\n",
       "  'd001.s048',\n",
       "  'd001.s049',\n",
       "  'd001.s090',\n",
       "  'd001.s128',\n",
       "  'd001.s129',\n",
       "  'd001.s130',\n",
       "  'd001.s131',\n",
       "  'd001.s132',\n",
       "  'd001.s133',\n",
       "  'd001.s134',\n",
       "  'd001.s135',\n",
       "  'd001.s136'],\n",
       " 'd001.s133': ['d001.s033',\n",
       "  'd001.s042',\n",
       "  'd001.s049',\n",
       "  'd001.s083',\n",
       "  'd001.s129',\n",
       "  'd001.s130',\n",
       "  'd001.s131',\n",
       "  'd001.s132',\n",
       "  'd001.s133',\n",
       "  'd001.s134',\n",
       "  'd001.s135',\n",
       "  'd001.s136'],\n",
       " 'd001.s134': ['d001.s007',\n",
       "  'd001.s023',\n",
       "  'd001.s029',\n",
       "  'd001.s065',\n",
       "  'd001.s130',\n",
       "  'd001.s131',\n",
       "  'd001.s132',\n",
       "  'd001.s133',\n",
       "  'd001.s134',\n",
       "  'd001.s135',\n",
       "  'd001.s136'],\n",
       " 'd001.s135': ['d001.s033',\n",
       "  'd001.s042',\n",
       "  'd001.s049',\n",
       "  'd001.s110',\n",
       "  'd001.s131',\n",
       "  'd001.s132',\n",
       "  'd001.s133',\n",
       "  'd001.s134',\n",
       "  'd001.s135',\n",
       "  'd001.s136'],\n",
       " 'd001.s136': ['d001.s031',\n",
       "  'd001.s052',\n",
       "  'd001.s095',\n",
       "  'd001.s120',\n",
       "  'd001.s132',\n",
       "  'd001.s133',\n",
       "  'd001.s134',\n",
       "  'd001.s135',\n",
       "  'd001.s136']}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(context_ids[2]), context_ids[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize时，一些词可能会产生多个token，如tokenizer.encode('absenteeism'.lower()) == [10040, 3051, 1863]\n",
    "context_output_mask[3],len(context_output_mask[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('objective%1:09:00::',\n",
       " 'objective+n',\n",
       " ['objective%1:09:00::', 'objective%1:06:00::'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[3], example_keys[3], gloss_dict[example_keys[3]][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 7, 20, 25, 34, 39, 41, 46, 52, 58, 67]\n",
      "[[9, 13, 5, 2, 3, 15, 8], [3, 4, 3, 8, 4, 19, 4, 3, 1, 2, 2, 1, 2], [4, 49, 4, 4, 8], [4, 2, 1, 4, 2, 3, 3, 5, 5], [25, 4, 2, 1, 4], [9, 4], [13, 1, 1, 4, 3], [6, 3, 3, 4, 2, 7], [13, 4, 4, 3, 2, 3], [4, 1, 3, 3, 4, 9, 4, 7, 4]]\n",
      "373\n"
     ]
    }
   ],
   "source": [
    "sent_id, sent_seg = [], []\n",
    "key_len_list = []\n",
    "for in_index, inst in enumerate(instances):\n",
    "    s_id = '.'.join(inst.split('.')[:-1])\n",
    "    if s_id not in sent_id:\n",
    "        sent_id.append(s_id)\n",
    "        sent_seg.append(in_index)\n",
    "sent_seg.append(len(instances))\n",
    "print(sent_seg)\n",
    "# gloss_dict: [0] definition_tokenize, [1] definition_mask, [2] sense_keys\n",
    "for seg_index, seg in enumerate(sent_seg[:-1]):\n",
    "    key_len_list.append([len(gloss_dict[key][2]) for key in example_keys[seg:sent_seg[seg_index + 1]]])\n",
    "print(key_len_list)\n",
    "total_sense = sum(sum(key_len_list, []))\n",
    "print(total_sense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_output1: torch.Size([10, 260, 768])\n",
      "context_output2: torch.Size([67, 768])\n",
      "context_output: torch.Size([67, 768])\n",
      "torch.Size([373, 32])\n",
      "torch.Size([373, 32])\n",
      "gloss_out_all: torch.Size([373, 32, 768])\n",
      "[245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372]\n",
      "[245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372]\n",
      "[245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372]\n",
      "[245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372]\n",
      "[245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372]\n",
      "[245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372]\n",
      "[245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372]\n",
      "[258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372]\n",
      "[258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372]\n",
      "[258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372]\n",
      "[258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372]\n",
      "[258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372]\n",
      "[258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372]\n",
      "[258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372]\n",
      "[258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372]\n",
      "[258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372]\n",
      "[258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372]\n",
      "[258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372]\n",
      "[258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372]\n",
      "[258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372]\n",
      "[280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372]\n",
      "[280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372]\n",
      "[280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372]\n",
      "[280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372]\n",
      "[280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372]\n",
      "[305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372]\n",
      "[305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372]\n",
      "[305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372]\n",
      "[305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372]\n",
      "[305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372]\n",
      "[305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372]\n",
      "[305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372]\n",
      "[305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372]\n",
      "[305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372]\n",
      "[334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372]\n",
      "[334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372]\n",
      "[334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372]\n",
      "[334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372]\n",
      "[334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372]\n",
      "[]\n",
      "[]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244]\n",
      "att_out: torch.Size([373, 768])\n",
      "current_example_keys: ['long+a', 'be+v', 'review+v', 'objective+n', 'benefit+n', 'service+n', 'program+n']\n",
      "current_key_len: [9, 13, 5, 2, 3, 15, 8]\n",
      "current_context_output: torch.Size([7, 768])\n",
      "current_insts: ['d000.s000.t000', 'd000.s000.t001', 'd000.s000.t002', 'd000.s000.t003', 'd000.s000.t004', 'd000.s000.t005', 'd000.s000.t006']\n",
      "current_labels: ['long%3:00:02::', 'be%2:42:03::', 'review%2:31:00::', 'objective%1:09:00::', 'benefit%1:21:00::', 'service%1:04:07::', 'program%1:09:01::']\n",
      "gat_out: torch.Size([55, 768])\n",
      "c_senses: ['long%3:00:02::', 'long%3:00:01::', 'long%5:00:00:tall:00', 'long%3:00:00::', 'long%3:00:05::', 'long%3:00:04::', 'long%5:00:00:unsound:00', 'long%5:00:00:provident:00', 'long%5:00:00:abundant:00', 'be%2:42:03::', 'be%2:42:06::', 'be%2:42:05::', 'be%2:42:00::', 'be%2:42:04::', 'be%2:42:07::', 'be%2:42:02::', 'be%2:41:00::', 'be%2:42:08::', 'be%2:40:00::', 'be%2:42:01::', 'be%2:42:13::', 'be%2:42:09::', 'review%2:31:00::', 'review%2:32:00::', 'review%2:31:02::', 'review%2:31:04::', 'review%2:31:01::', 'objective%1:09:00::', 'objective%1:06:00::', 'benefit%1:21:00::', 'benefit%1:07:00::', 'benefit%1:10:00::', 'service%1:04:08::', 'service%1:04:00::', 'service%1:04:01::', 'service%1:14:05::', 'service%1:04:07::', 'service%1:14:00::', 'service%1:18:00::', 'service%1:07:00::', 'service%1:06:00::', 'service%1:04:03::', 'service%1:04:09::', 'service%1:04:02::', 'service%1:04:04::', 'service%1:04:05::', 'service%1:04:06::', 'program%1:09:00::', 'program%1:09:01::', 'program%1:10:01::', 'program%1:10:04::', 'program%1:10:00::', 'program%1:10:05::', 'program%1:10:02::', 'program%1:04:00::']\n",
      "gloss_output_pad: torch.Size([7, 15, 768])\n",
      "out: torch.Size([7, 15])\n"
     ]
    }
   ],
   "source": [
    "train_index = {}\n",
    "key_mat = dict()\n",
    "loss = 0.\n",
    "gloss_sz = 0\n",
    "context_sz = 0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    context_ids = context_ids.cuda()\n",
    "    context_attn_mask = context_attn_mask.cuda()\n",
    "    # 输出一个batch中，所有多义词对应的embeddings\n",
    "    context_output = model.context_forward(context_ids, context_attn_mask, context_output_mask)\n",
    "    print('context_output:',context_output.shape)\n",
    "    max_len_gloss = max(\n",
    "            sum([[torch.sum(mask_list).item() for mask_list in gloss_dict[key][1]] for key in example_keys],\n",
    "                []))\n",
    "    gloss_ids_all = torch.cat([gloss_dict[key][0][:, :max_len_gloss] for key in example_keys])\n",
    "    gloss_attn_mask_all = torch.cat([gloss_dict[key][1][:, :max_len_gloss] for key in example_keys])\n",
    "    print(gloss_ids_all.shape)\n",
    "    print(gloss_attn_mask_all.shape)\n",
    "    gloss_ids = gloss_ids_all.cuda()\n",
    "    gloss_attn_mask = gloss_attn_mask_all.cuda()\n",
    "    gat_out_all = model.gat_forward(gloss_ids, gloss_attn_mask, key_len_list, instances, train_index, b)\n",
    "    \n",
    "    for seg_index, seg in enumerate(sent_seg[:-1]):\n",
    "        current_example_keys = example_keys[seg: sent_seg[seg_index + 1]]\n",
    "        print('current_example_keys:',current_example_keys)\n",
    "        current_key_len = key_len_list[seg_index]\n",
    "        print('current_key_len:',current_key_len)\n",
    "        current_context_output = context_output[seg: sent_seg[seg_index + 1], :]\n",
    "        print('current_context_output:',current_context_output.shape)\n",
    "        current_insts = instances[seg: sent_seg[seg_index + 1]]\n",
    "        print('current_insts:',current_insts)\n",
    "        current_labels = labels[seg: sent_seg[seg_index + 1]]\n",
    "        print('current_labels:',current_labels)\n",
    "        gat_out = gat_out_all[\n",
    "                        sum(sum(key_len_list[:seg_index], [])): sum(sum(key_len_list[:seg_index + 1], [])),\n",
    "                        :]\n",
    "        print('gat_out:',gat_out.shape) # 55x768\n",
    "        c_senses = sum([gloss_dict[key][2] for key in current_example_keys], [])\n",
    "        print('c_senses:',c_senses)\n",
    "        gat_cpu = gat_out.cpu()\n",
    "        for k_index, key in enumerate(c_senses):\n",
    "            key_mat[key] = gat_cpu[k_index:k_index + 1]\n",
    "        \n",
    "        gloss_output_pad = torch.cat([F.pad(\n",
    "                gat_out[sum(current_key_len[:i]): sum(current_key_len[:i+1]), :],\n",
    "                pad=[0, 0, 0, max(current_key_len) - j]).unsqueeze(0) for i, j in enumerate(current_key_len)], dim=0)\n",
    "        print('gloss_output_pad:',gloss_output_pad.shape) # gloss_output_pad: torch.Size([7, 15, 768])\n",
    "        out = torch.bmm(gloss_output_pad, current_context_output.unsqueeze(2)).squeeze(2)\n",
    "        print('out:',out.shape)\n",
    "        gloss_sz += gat_out.size(0)\n",
    "        context_sz += 1\n",
    "        \n",
    "        # for j, (key, label) in enumerate(zip(current_example_keys, current_labels)):\n",
    "        #     idx = gloss_dict[key][2].index(label)\n",
    "        #     label_tensor = torch.tensor([idx]).cuda()\n",
    "        #     train_index[current_insts[j]] = out[j:j + 1, :current_key_len[j]].argmax(dim=1).item()\n",
    "        #     loss += F.cross_entropy(out[j:j + 1, :current_key_len[j]], label_tensor)\n",
    "        #     all_instance += 1\n",
    "        #     if out[j:j + 1, :current_key_len[j]].argmax(dim=1).item() == idx: \n",
    "        #         pre_instance += 1\n",
    "        #     if idx == 0:\n",
    "        #         mfs_instance += 1\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101, 1293, 1263,  ...,    0,    0,    0],\n",
       "        [ 101, 1293, 1263,  ...,    0,    0,    0],\n",
       "        [ 101, 1293, 1263,  ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [ 101, 1202, 1128,  ...,    0,    0,    0],\n",
       "        [ 101, 1138, 1128,  ..., 5913,  119,  102],\n",
       "        [ 101, 1110, 1122,  ...,    0,    0,    0]], device='cuda:0')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 303])\n"
     ]
    }
   ],
   "source": [
    "def create_hypergraph_matrix(context_ids, context_attn_mask):\n",
    "    # 找出所有不重复的单词\n",
    "    unique_tokens = torch.unique(context_ids)\n",
    "    \n",
    "    # 移除101, 102和0\n",
    "    unique_tokens = unique_tokens[~torch.isin(unique_tokens, torch.tensor([0, 101, 102]))]\n",
    "    \n",
    "    # 创建一个映射，将unique token映射到它的位置\n",
    "    token_to_idx = {token.item(): idx for idx, token in enumerate(unique_tokens)}\n",
    "    \n",
    "    num_sentences, _ = context_ids.shape\n",
    "    num_unique_tokens = len(unique_tokens)\n",
    "    \n",
    "    # 初始化超图关联矩阵为0\n",
    "    H = torch.zeros(num_sentences, num_unique_tokens)\n",
    "    \n",
    "    for i in range(num_sentences):\n",
    "        # 获取句子的有效tokens（由attention mask确定）\n",
    "        valid_tokens = context_ids[i, context_attn_mask[i].bool()]\n",
    "        \n",
    "        # 对于每个有效token，标记其在关联矩阵中的位置为1（只有当token在unique_tokens中时）\n",
    "        for token in valid_tokens:\n",
    "            if token.item() in token_to_idx:  # 这里增加了一个条件判断\n",
    "                H[i, token_to_idx[token.item()]] = 1\n",
    "    \n",
    "    return H,token_to_idx\n",
    "\n",
    "# # 示例\n",
    "# context_ids = torch.randint(0, 30000, (10, 260))  # 随机的token ids\n",
    "# context_attn_mask = torch.ones((10, 260))  # 假设所有位置都是有效的\n",
    "\n",
    "H,token_to_idx = create_hypergraph_matrix(context_ids.cpu(), context_attn_mask.cpu())\n",
    "print(H.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{112: 0,\n",
       " 117: 1,\n",
       " 118: 2,\n",
       " 119: 3,\n",
       " 136: 4,\n",
       " 169: 5,\n",
       " 170: 6,\n",
       " 175: 7,\n",
       " 176: 8,\n",
       " 188: 9,\n",
       " 1103: 10,\n",
       " 1104: 11,\n",
       " 1105: 12,\n",
       " 1106: 13,\n",
       " 1107: 14,\n",
       " 1108: 15,\n",
       " 1110: 16,\n",
       " 1111: 17,\n",
       " 1112: 18,\n",
       " 1113: 19,\n",
       " 1114: 20,\n",
       " 1115: 21,\n",
       " 1116: 22,\n",
       " 1118: 23,\n",
       " 1121: 24,\n",
       " 1122: 25,\n",
       " 1126: 26,\n",
       " 1128: 27,\n",
       " 1129: 28,\n",
       " 1132: 29,\n",
       " 1133: 30,\n",
       " 1134: 31,\n",
       " 1137: 32,\n",
       " 1138: 33,\n",
       " 1141: 34,\n",
       " 1142: 35,\n",
       " 1144: 36,\n",
       " 1146: 37,\n",
       " 1147: 38,\n",
       " 1149: 39,\n",
       " 1150: 40,\n",
       " 1151: 41,\n",
       " 1152: 42,\n",
       " 1155: 43,\n",
       " 1156: 44,\n",
       " 1157: 45,\n",
       " 1158: 46,\n",
       " 1159: 47,\n",
       " 1165: 48,\n",
       " 1168: 49,\n",
       " 1169: 50,\n",
       " 1170: 51,\n",
       " 1172: 52,\n",
       " 1175: 53,\n",
       " 1180: 54,\n",
       " 1183: 55,\n",
       " 1184: 56,\n",
       " 1185: 57,\n",
       " 1190: 58,\n",
       " 1191: 59,\n",
       " 1194: 60,\n",
       " 1196: 61,\n",
       " 1202: 62,\n",
       " 1206: 63,\n",
       " 1207: 64,\n",
       " 1209: 65,\n",
       " 1211: 66,\n",
       " 1216: 67,\n",
       " 1218: 68,\n",
       " 1231: 69,\n",
       " 1240: 70,\n",
       " 1250: 71,\n",
       " 1251: 72,\n",
       " 1256: 73,\n",
       " 1260: 74,\n",
       " 1263: 75,\n",
       " 1269: 76,\n",
       " 1277: 77,\n",
       " 1290: 78,\n",
       " 1292: 79,\n",
       " 1293: 80,\n",
       " 1294: 81,\n",
       " 1295: 82,\n",
       " 1298: 83,\n",
       " 1315: 84,\n",
       " 1321: 85,\n",
       " 1329: 86,\n",
       " 1343: 87,\n",
       " 1383: 88,\n",
       " 1385: 89,\n",
       " 1388: 90,\n",
       " 1389: 91,\n",
       " 1396: 92,\n",
       " 1402: 93,\n",
       " 1419: 94,\n",
       " 1433: 95,\n",
       " 1444: 96,\n",
       " 1494: 97,\n",
       " 1541: 98,\n",
       " 1554: 99,\n",
       " 1555: 100,\n",
       " 1561: 101,\n",
       " 1583: 102,\n",
       " 1586: 103,\n",
       " 1606: 104,\n",
       " 1612: 105,\n",
       " 1633: 106,\n",
       " 1660: 107,\n",
       " 1679: 108,\n",
       " 1684: 109,\n",
       " 1694: 110,\n",
       " 1712: 111,\n",
       " 1714: 112,\n",
       " 1755: 113,\n",
       " 1779: 114,\n",
       " 1788: 115,\n",
       " 1821: 116,\n",
       " 1832: 117,\n",
       " 1859: 118,\n",
       " 1863: 119,\n",
       " 1878: 120,\n",
       " 1895: 121,\n",
       " 1897: 122,\n",
       " 1937: 123,\n",
       " 1948: 124,\n",
       " 1957: 125,\n",
       " 2049: 126,\n",
       " 2214: 127,\n",
       " 2218: 128,\n",
       " 2222: 129,\n",
       " 2228: 130,\n",
       " 2237: 131,\n",
       " 2273: 132,\n",
       " 2283: 133,\n",
       " 2326: 134,\n",
       " 2329: 135,\n",
       " 2354: 136,\n",
       " 2366: 137,\n",
       " 2396: 138,\n",
       " 2437: 139,\n",
       " 2450: 140,\n",
       " 2497: 141,\n",
       " 2509: 142,\n",
       " 2513: 143,\n",
       " 2526: 144,\n",
       " 2552: 145,\n",
       " 2569: 146,\n",
       " 2582: 147,\n",
       " 2610: 148,\n",
       " 2616: 149,\n",
       " 2653: 150,\n",
       " 2663: 151,\n",
       " 2683: 152,\n",
       " 2686: 153,\n",
       " 2732: 154,\n",
       " 2747: 155,\n",
       " 2801: 156,\n",
       " 2952: 157,\n",
       " 2975: 158,\n",
       " 3004: 159,\n",
       " 3026: 160,\n",
       " 3051: 161,\n",
       " 3055: 162,\n",
       " 3068: 163,\n",
       " 3098: 164,\n",
       " 3106: 165,\n",
       " 3121: 166,\n",
       " 3210: 167,\n",
       " 3239: 168,\n",
       " 3254: 169,\n",
       " 3271: 170,\n",
       " 3317: 171,\n",
       " 3370: 172,\n",
       " 3380: 173,\n",
       " 3395: 174,\n",
       " 3442: 175,\n",
       " 3545: 176,\n",
       " 3549: 177,\n",
       " 3576: 178,\n",
       " 3634: 179,\n",
       " 3677: 180,\n",
       " 3719: 181,\n",
       " 3738: 182,\n",
       " 3779: 183,\n",
       " 3784: 184,\n",
       " 3869: 185,\n",
       " 3918: 186,\n",
       " 3945: 187,\n",
       " 3953: 188,\n",
       " 3970: 189,\n",
       " 4031: 190,\n",
       " 4035: 191,\n",
       " 4045: 192,\n",
       " 4069: 193,\n",
       " 4128: 194,\n",
       " 4129: 195,\n",
       " 4316: 196,\n",
       " 4481: 197,\n",
       " 4511: 198,\n",
       " 4570: 199,\n",
       " 4595: 200,\n",
       " 4615: 201,\n",
       " 4725: 202,\n",
       " 4727: 203,\n",
       " 4733: 204,\n",
       " 4841: 205,\n",
       " 4884: 206,\n",
       " 4929: 207,\n",
       " 5022: 208,\n",
       " 5053: 209,\n",
       " 5257: 210,\n",
       " 5320: 211,\n",
       " 5389: 212,\n",
       " 5438: 213,\n",
       " 5442: 214,\n",
       " 5455: 215,\n",
       " 5496: 216,\n",
       " 5497: 217,\n",
       " 5498: 218,\n",
       " 5671: 219,\n",
       " 5873: 220,\n",
       " 5913: 221,\n",
       " 5964: 222,\n",
       " 5986: 223,\n",
       " 5997: 224,\n",
       " 6171: 225,\n",
       " 6182: 226,\n",
       " 6245: 227,\n",
       " 6303: 228,\n",
       " 6312: 229,\n",
       " 6315: 230,\n",
       " 6385: 231,\n",
       " 6461: 232,\n",
       " 6555: 233,\n",
       " 6678: 234,\n",
       " 6730: 235,\n",
       " 6796: 236,\n",
       " 7138: 237,\n",
       " 7485: 238,\n",
       " 7533: 239,\n",
       " 7570: 240,\n",
       " 7775: 241,\n",
       " 7815: 242,\n",
       " 8096: 243,\n",
       " 8179: 244,\n",
       " 8223: 245,\n",
       " 8313: 246,\n",
       " 8343: 247,\n",
       " 8455: 248,\n",
       " 8658: 249,\n",
       " 9193: 250,\n",
       " 9241: 251,\n",
       " 9674: 252,\n",
       " 9715: 253,\n",
       " 10040: 254,\n",
       " 10116: 255,\n",
       " 10124: 256,\n",
       " 10302: 257,\n",
       " 11283: 258,\n",
       " 11350: 259,\n",
       " 11736: 260,\n",
       " 11928: 261,\n",
       " 11932: 262,\n",
       " 12020: 263,\n",
       " 12826: 264,\n",
       " 12949: 265,\n",
       " 13445: 266,\n",
       " 13588: 267,\n",
       " 13856: 268,\n",
       " 13890: 269,\n",
       " 13909: 270,\n",
       " 13980: 271,\n",
       " 14007: 272,\n",
       " 14629: 273,\n",
       " 14705: 274,\n",
       " 14785: 275,\n",
       " 14955: 276,\n",
       " 15187: 277,\n",
       " 15851: 278,\n",
       " 16238: 279,\n",
       " 16300: 280,\n",
       " 17038: 281,\n",
       " 17109: 282,\n",
       " 17780: 283,\n",
       " 18222: 284,\n",
       " 18667: 285,\n",
       " 18698: 286,\n",
       " 18748: 287,\n",
       " 18750: 288,\n",
       " 19105: 289,\n",
       " 21262: 290,\n",
       " 22407: 291,\n",
       " 22977: 292,\n",
       " 23804: 293,\n",
       " 23951: 294,\n",
       " 24043: 295,\n",
       " 24977: 296,\n",
       " 25522: 297,\n",
       " 25667: 298,\n",
       " 26237: 299,\n",
       " 26332: 300,\n",
       " 26656: 301,\n",
       " 27841: 302}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_to_idx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wsd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
